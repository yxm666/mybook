{"./":{"url":"./","title":"书籍介绍","keywords":"","body":"书籍介绍 ​ 本教程通过观看数据结构与算法之美与📚《大话数据结构》和 严慧敏的📚《数据结构》进行知识总结，参考笔记与代码有小争哥的github库和基于此的笔记总结 Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-17 11:45:28 "},"数据结构与算法.html":{"url":"数据结构与算法.html","title":"入门篇","keywords":"","body":"01. 入门篇 数据结构与算法 数据结构与算法的定义 ​ 从广义上讲，数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。 图书管理员为了方便查找，一般会将书籍分门别类进行“存储”。按照一定规律编号，就是书籍这种“数据”的存储结构。 查找一本书有很多种办法，你可以一本一本地找，也可以先根据书籍类别的编号，是人文，还是科学、计算机，来定位书架，然后再依次查找。笼统地说，这些查找方法都是算法。 从狭义上讲，数据结构和算法，是指某些著名的队列、栈、堆、二分查找、动态规划等。 这些都是前人从很多实际操作场景中抽象出来的，经过非常多的求证和检验，可以高效地帮助我们解决很多实际的开发问题。 数据结构与算法的关系 数据结构和算法是相辅相成的。 数据结构是为算法服务的，算法要作用在特定的数据结构之上。 因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。 比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。 数据结构是静态的，它只是组织数据的一种方式。如果不在它的基础上操作、构建算法，孤立存在的数据结构就是没用的。 数据结构与算分整体框架 20 个最常用的、最基础数据结构与算法： 10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树； 10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。 掌握了这些基础的数据结构和算法，再学更加复杂的数据结构和算法，就会非常容易、非常快。 在学习数据结构和算法的过程中，应当学习它的： “来历” “自身的特点” “适合解决的问题” 以及“实际的应用场景”。 时间、空间复杂度分析 ​ 复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半。 事后统计法的局限性 1. 测试结果非常依赖测试环境 测试环境中硬件的不同会对测试结果有很大的影响。比如，我们拿同样一段代码，分别用 Intel Core i9 处理器和 Intel Core i3 处理器来运行，不用说，i9 处理器要比 i3 处理器执行的速度快很多。还有，比如原本在这台机器上 a 代码执行的速度比 b 代码要快，等我们换到另一台机器上时，可能会有截然相反的结果。 2. 测试结果受数据规模的影响很大 对同一个排序算法，待排序数据的有序度不一样，排序的执行时间就会有很大的差别。极端情况下，如果数据已经是有序的，那排序算法不需要做任何操作，执行时间就会非常短。除此之外，如果测试数据规模太小，测试结果可能无法真实地反应算法的性能。比如，对于小规模的数据排序，插入排序可能反倒会比快速排序要快！ 所以，我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法。这就是时间、空间复杂度分析方法。 大 O 复杂度表示法 算法的执行效率，粗略地讲，就是算法代码执行的时间。 但是，如何在不运行代码的情况下，用“肉眼”得到一段代码的执行时间呢？ 这里有段非常简单的代码，求 1,2,3…n 的累加和。 int cal(int n) { int sum = 0; int i = 1; for (; i 从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。 第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 $2n unit_time$ 的执行时间，所以这段代码总的执行时间就是 $(2n+2)unit_time$。可以看出来，所有代码的执行时间 T(n) 与每行代码的执行次数成正比。 按照这个分析思路，我们再来看这段代码。 int cal(int n) { int sum = 0; int i = 1; int j = 1; for (; i 依旧假设每个语句的执行时间是 unit_time。那这段代码的总执行时间 T(n) 是多少呢？ 第 2、3、4 行代码，每行都需要 1 个 unit_time 的执行时间，第 5、6 行代码循环执行了 n 遍，需要$2nunit_time$ 的执行时间，第 7、8 行代码循环执行了 $n^2$遍，所以需要 $2n^{2} unit_time$ 的执行时间。所以，整段代码总的执行时间$T(n) = (2n^2+2n+3)*unit_time$ . 需要 $2n unit_time$ 的执行时间，第 7、8 行代码循环执行了 $n^{2}$遍，所以需要 $2n^{2} unit_time$ 的执行时间。所以，整段代码总的执行时间 $T(n) = (2n^2+2n+3)*unit_time$。 尽管不知道 unit_time 的具体值，但所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比。 把这个规律总结成一个公式: T(n)=O(f(n)) T(n)=O(f(n)) T(n)=O(f(n)) T(n) 表示代码执行的时间；n 表示数据规模的大小； f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。 公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。 所以，第一个例子中的 $T(n) = O(2n+2)$，第二个例子中的 $T(n) = O(2n^2+2n+3)$。这就是大 O 时间复杂度表示法。大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。 当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：$T(n) = O(n)； T(n) = O(n^2)$。 时间复杂度分析 时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。 三个比较实用的分析方法 1. 只关注循环执行次数最多的一段代码 大 O 这种复杂度表示方法只是表示一种变化趋势。通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。 以前面的例子举例： int cal(int n) { int sum = 0; int i = 1; for (; i 其中第 2、3 行代码都是常量级的执行时间，与 n 的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了 n 次，所以总的时间复杂度就是 O(n)。 2. 加法法则 总复杂度等于量级最大的那段代码的复杂度 int cal(int n) { int sum_1 = 0; int p = 1; for (; p 这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。 第一段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。 当 n 无限大的时候，尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大都可以忽略掉。因为它本身对增长趋势并没有影响。 第二段代码和第三段代码的时间复杂度分别是$O(n)$ 和 $O(n^2)$。 综合这三段代码的时间复杂度，取其中最大的量级。所以，整段代码的时间复杂度就为$O(n^2)$。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽象成公式就是： 如果 $T1(n)=O(f(n))，T2(n)=O(g(n))$；那么 $T(n)=T1(n)+T2(n)=max(O(f(n))$, $O(g(n))) =O(max(f(n), g(n)))$. 3.乘法法则 嵌套代码的复杂度等于嵌套内外代码复杂度的乘积 如果 $T1(n)=O(f(n))$，$T2(n)=O(g(n))$；那么 $T(n)=T1(n)T2(n)=O(f(n))O(g(n))=O(f(n)*g(n))$. 也就是说，假设 T1(n) = O(n)，$T2(n) = O(n^2)$，则 $T1(n) T2(n) = O(n^3)$。落实到具体的代码上，我们可以把乘法法则看成是*嵌套循环，举个例子: int cal(int n) { int ret = 0; int i = 1; for (; i 单独看 cal() 函数。假设 f() 只是一个普通的操作，那第 4～6 行的时间复杂度就是，$T_1(n) = O(n)$。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 $T_2(n) = O(n)$，所以，整个 cal() 函数的时间复杂度就是，$T(n) = T_1(n) T_2(n) = O(nn) = O(n^2)$。 多项式时间复杂度分析 常见的复杂度量级（按数量级递增）: 多项式量级： 常量阶：$O(1)$ 对数阶：$O(log\\ n)$ 线性阶：$O(n)$ 线性对数阶：$nO(log\\ n)$ 平方阶：$O(n^2)$、 立方阶：$O(n^3)$、……、 K次方阶：$O(n^k)$ 非多项式量级： 指数阶：$O(2^n)$ 阶乘阶： $O(n!)$ 可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：$O(2^n)$ 和 $O(n!)$。 当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。 我们主要来看几种常见的多项式时间复杂度。 1. O(1)1.O(1) 首先你必须明确一个概念，O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是 O(1)，而不是 O(3)。 int i = 8; int j = 6; int sum = i + j;Copy to clipboardErrorCopied 只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。 2. O(logn)、O(nlogn)2.O(log**n)、O(nlogn) 例子： i=1; while (i 第三行代码是循环执行次数最多的，只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。 实际上，变量 i 的取值就是一个等比数列。如果把它列出来： 2^{0} \\quad 2^{1} \\quad 2^{2} \\cdots 2^{k} \\cdots 2^{x}=n202122⋯2k⋯2x=n 通过 2^x=n2x=n 得 x=log_2nx=log2n，所以，这段代码的时间复杂度就是 O(log_2n)O(log2n)。 例子： i=1; while (i 这段代码的时间复杂度为 O(log_3n)O(log3n)。 实际上，可以把所有对数阶的时间复杂度都记为 O(log\\ n)O(log n)。 log_3n= log_3 2 log_2 nlog3n=log32∗log2n，所以 O(log_3 n) = O(C log_2 n)O(log3n)=O(C∗log2n)，其中 C=log_32C=log32 是一个常量。 因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)O(log**n)。 如果一段代码的时间复杂度是 O(logn)O(log**n)，循环执行 n 遍，时间复杂度就是 O(logn)O(log**n)了。 归并排序、快速排序的时间复杂度都是 O(nlogn)O(nlogn)。 3. O(m+n)、O(mn)3.O(m+n)、O(m∗n*) 这种时间复杂度，代码的复杂度由两个数据的规模来决定。 先看代码： int cal(int m, int n) { int sum_1 = 0; int i = 1; for (; i m 和 n 是表示两个数据规模，无法事先评估 m 和 n 谁的量级大，无法忽略其中一个，所以上面代码的时间复杂度就是 O(m+n)。 针对这种情况，加法规则为：T_1(m) + T_2(n) = O(f(m) + g(n))T1(m)+T2(n)=O(f(m)+g(n))。 但是乘法法则继续有效：T_1(m)T_2(n) = O(f(m) f(n))T1(m)∗T2(n)=O(f(m)∗f(n))。 空间复杂度分析 空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的额外存储空间与数据规模之间的增长关系。 举个弱智的例子： void print(int n) { int i = 0; int[] a = new int[n]; for (i; i = 0; --i) { print out a[i] } }Copy to clipboardErrorCopied 第 2 行代码中，申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以可以忽略。 第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。 我们常见的空间复杂度就是 O(1)、O(n)、O(n^2)O(1)、O(n)、O(n2)，像 O(logn)、O(nlogn)O(log**n)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。 渐进复杂度小结 渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有： O(1)、O(logn)、O(n)、O(nlogn)、O(n^2)O(1)、O(log**n)、O(n)、O(nlogn)、O(n2)。 渐进时间，渐进空间复杂度分析与是宿主平台无关的，能够让我们对我们的程序或算法有一个大致的认识，让我们知道，比如在最坏的情况下程序的执行效率如何。 算法1的时间复杂度是O(n)O(n)，算法2的时间复杂度是O(logn)O(log**n)，能立刻就对不同的算法有一个“效率”上的感性认识。 渐进式时间，空间复杂度分析只是一个理论模型，只能提供给粗略的估计分析，我们不能直接断定就觉得O(logN)的算法一定优于O(n), 针对不同的宿主环境，不同的数据集，不同的数据量的大小，在实际应用上面可能真正的性能会不同，针对不同的实际情况，进而进行一定的性能基准测试是很有必要的，比如在同一批手机上(同样的硬件，系统等等)进行横向基准测试，进而选择适合特定应用场景下的最有算法。 综上所述，渐进式时间，空间复杂度分析与性能基准测试并不冲突，而是相辅相成的，但是一个低阶的时间复杂度程序有极大的可能性会优于一个高阶的时间复杂度程序，所以在实际编程中，时刻关心理论时间，空间度模型是有助于产出效率高的程序的，同时，因为渐进式时间，空间复杂度分析只是提供一个粗略的分析模型，因此也不会浪费太多时间，重点在于在编程时，要具有这种复杂度分析的思维。 四种情况下时间复杂度分析 最好情况时间复杂度（best case time complexity） 最坏情况时间复杂度（worst case time complexity） 平均情况时间复杂度（average case time complexity） 均摊时间复杂度（amortized time complexity） 在一个无序的数组（array）中，查找变量 x 出现的位置。如果没有找到，就返回 -1。这段代码的复杂度是 O(n)，其中，n 代表数组的长度。 在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，因为有可能中途找到就可以提前结束循环了： // n 表示数组 array 的长度 int find(int[] array, int n, int x) { int i = 0; int pos = -1; for (; i 要查找的变量 x 可能出现在数组的任意位置。 如果数组中第一个元素正好是要查找的变量 x，那时间复杂度就是 O(1)。 但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。 所以，不同的情况下，这段代码的时间复杂度是不一样的。 最好、最坏情况时间复杂度 为了表示代码在不同情况下的不同时间复杂度，引入最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。 最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。 最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。 平均情况时间复杂度 平均情况时间复杂度，可简称为平均时间复杂度。 平均时间复杂度的可以叫加权平均时间复杂度或者期望时间复杂度。 引入概率之后，前面那段代码的加权平均值为\\frac{3n+1}{4}43n+1 。用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)。 只有同一块代码在不同的情况下，时间复杂度有量级的差距，才会使用最好最差平均三种复杂度表示法来区分。 均摊时间复杂度 均摊时间复杂度 ，对应的分析方法，摊还分析（或者叫平摊分析）。 Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-17 13:15:55 "},"Array.html":{"url":"Array.html","title":"02. 数组","keywords":"","body":"02.数组 数组是一种最基础的数据结构，在大部分编程语言中，数组都是从 0 开始编号的。 线性表与非线性表 线性表（Linear List），就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向，包括数组，链表、队列、栈等。 数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。 非线性表，数据之间并不是简单的前后关系，有二叉树、堆、图等，如下图： 数组实现随机访问的方法 数组使用了连续的内存空间和相同类型的数据。使得它可以“随机访问”，但同时也让数组的删除、插入等操作变得非常低效，为了保证连续性，就需要做大量的数据搬移工作。 数组是如何实现根据下标随机访问数组呢？ 以一个长度为 10 的 int 类型的数组 int[] a = new int[10]为例。 计算机会给每个内存单元分配一个地址，并通过地址来访问内存中的数据。 下图中，假设计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。 当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址： a[i]_address = base_address + i * data_type_sizeCopy to clipboardErrorCopied data_type_size 表示数组中每个元素的大小。 上面的数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。 数组查找的时间复杂度 数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。 排好序的数组用二分查找，时间复杂度是 O(logn)； 顺序查找，最好时间复杂度为 O(1)，最差时间复杂度为O(n)，平均时间复杂度为O(n) 数组的低效操作 插入操作 假设数组的长度为 n，如果将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来给新来的数据，需要将第 k～n 这部分的元素都顺序地往后挪一位。 如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 \\frac{1+2+…n}{n}=O(n)n1+2+…n=O(n)。 如果数组中的数据是有序的，在某个位置插入一个新的元素时，就必须搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。可以直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。 假设数组 a[10] 中存储了如下 5 个元素：a，b，c，d，e。 现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放入到 a[5]，将 a[2] 赋值为 x 即可： 利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。这个处理思想在快排中也会用到。 删除操作 如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。 如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。 实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。可以将多次删除操作集中在一起执行。 比如数组 a[10] 中存储了 8 个元素：a，b，c，d，e，f，g，h。要依次删除 a，b，c 三个元素： 为了避免 d，e，f，g，h 这几个数据会被搬移三次，可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，再触发执行一次真正的删除操作。 这有点像是 JVM 标记清除垃圾回收算法的核心思想。 警惕数组的访问越界问题 先分析一下这段 C 语言代码的运行结果： int main(int argc, char* argv[]){ int i = 0; int arr[3] = {0}; for(; i 这段代码的运行结果并非是打印三行“hello word”，而是会无限打印“hello world”。 因为，数组大小为 3，a[0]，a[1]，a[2]，而 a[3] 访问越界，在 C 语言中，a[3] 被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，其他高级语言一般会报角标越界异常。 那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。 访问数组的本质就是访问一段连续内存，在 C 语言中只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。 C语言把数组越界检查的工作丢给程序员来做，但 Java 本身就会做越界检查，比如下面这几行 Java 代码，就会抛出 java.lang.ArrayIndexOutOfBoundsException。 int[] a = new int[3]; a[3] = 10;c 容器vs数组 针对数组类型，很多语言都提供了容器类，比如 Java 中的 ArrayList、C++ STL 中的 vector。 ArrayList 最大的优势就是可以将很多数组操作的细节封装起来。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是支持动态扩容。 数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。 如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。 扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。 比如我们要从数据库中取出 10000 条数据放入 ArrayList。我们看下面这几行代码，你会发现，相比之下，事先指定数据大小可以省掉很多次内存申请和数据搬移操作。 ArrayList users = new ArrayList(10000); for (int i = 0; i 有些时候用数组会更合适些： Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。 当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList array。 总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器。 为什么数组要从 0 开始编号? 为什么数组要从 0 开始编号，而不是从 1 开始呢？ 从 1 开始不是更符合人类的思维习惯吗？ 从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。 从 0 开始编号，数组 a[k] 的内存寻址公式为： a[k]_address = base_address + k * type_sizeCopy to clipboardErrorCopied 从 1 开始编号，数组 a[k] 的内存寻址公式为： a[k]_address = base_address + (k-1)*type_sizeCopy to clipboardErrorCopied 对比两个公式，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。 所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。另外，C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。 当然，并不是所有语言的数组都是从 0 开始计数的，比如 Matlab。 二维数组的内存寻址公式 对于 m * n 的数组，`a[i][j] (i的地址为： address = base_address + (i*n+j)*type_size 数组的C语言实现 #include \"stdio.h\" #include \"stdlib.h\" #include \"math.h\" #include \"time.h\" // 定义4种表示结果的 宏定义 #define OK 1 #define ERROR 0 #define TRUE 1 #define FALSE 0 #define MAXSIZE 20 /* 存储空间初始分配量 */ typedef int Status; /* Status是函数的类型,其值是函数结果状态代码，如OK等 */ typedef int ElemType; /* ElemType类型根据实际情况而定，这里假设为int */ // Status 为int 类型 Status visit(ElemType c) { printf(\"%d \",c); return OK; } /* 定义一个结构体Sqlist 用以模拟数组的结构 ElemType为一个int类型数组 默认大小为20 */ typedef struct { ElemType data[MAXSIZE]; /* 数组，存储数据元素 */ int length; /* 线性表当前长度 */ }SqList; /* 初始化顺序线性表 */ Status InitList(SqList *L) { // 初始化数组 L->length=0; return OK; } /* 初始条件：顺序线性表L已存在。操作结果：若L为空表，则返回TRUE，否则返回FALSE */ Status ListEmpty(SqList L) { if(L.length==0) return TRUE; else return FALSE; } /* 初始条件：顺序线性表L已存在。操作结果：将L重置为空表 长度为0*/ Status ClearList(SqList *L) { L->length=0; return OK; } /* 初始条件：顺序线性表L已存在。操作结果：返回L中数据元素个数 */ int ListLength(SqList L) { return L.length; } /* 初始条件：顺序线性表L已存在，1≤i≤ListLength(L) */ /* 操作结果：用e返回L中第i个数据元素的值,注意i是指位置，第1个位置的数组是从0开始 */ Status GetElem(SqList L,int i,ElemType *e) { // 判断数组是否为空 判断是否小于1(因为默认lengh为0 这里的lengh与index不是一码事 需要注意) 判断i是否下标越界 if(L.length==0 || iL.length) return ERROR; // 传入的为指针 可以对传入的ElemType(即跟数组一样的类型)进行修改引用(Java叫法) \b修改值 // 下标是传入的值减去1 *e=L.data[i-1]; return OK; } /* 初始条件：顺序线性表L已存在 */ /* 操作结果：返回L中第1个与e满足关系的数据元素的位序。 */ /* 若这样的数据元素不存在，则返回值为0 */ int LocateElem(SqList L,ElemType e) { int i; // 数组为空 if (L.length==0) return 0; for(i=0;i=L.length) return 0; return i+1; } /* 初始条件：顺序线性表L已存在,1≤i≤ListLength(L)， */ /* 操作结果：在L中第i个位置之前插入新的数据元素e，L的长度加1 */ Status ListInsert(SqList *L,int i,ElemType e) { int k; if (L->length==MAXSIZE) /* 顺序线性表已经满 */ return ERROR; if (iL->length+1)/* 当i比第一位置小或者比最后一位置后一位置还要大时 */ return ERROR; // 插入的i是按照长度估算的 if (ilength) /* 若插入数据位置不在表尾 */ { // 将后面的元素 从最后依次向后移动 for(k=L->length-1;k>=i-1;k--) /* 将要插入位置之后的数据元素向后移动一位 */ // 将元素依次后移 L->data[k+1]=L->data[k]; } L->data[i-1]=e; /* 将新元素插入 */ // 数组长度加一 L->length++; return OK; } /* 初始条件：顺序线性表L已存在，1≤i≤ListLength(L) */ /* 操作结果：删除L的第i个数据元素，并用e返回其值，L的长度减1 */ Status ListDelete(SqList *L,int i,ElemType *e) { int k; if (L->length==0) /* 线性表为空 */ return ERROR; if (iL->length) /* 删除位置不正确 */ return ERROR; *e=L->data[i-1]; if (ilength) /* 如果删除不是最后位置 */ { // 删除位置 从前往后将位置前移 for(k=i;klength;k++)/* 将删除位置后继元素前移 */ L->data[k-1]=L->data[k]; } // 数组长度减1 L->length--; return OK; } /* 初始条件：顺序线性表L已存在 */ /* 操作结果：依次对L的每个数据元素输出 */ Status ListTraverse(SqList L) { int i; for(i=0;i=k;j--) { i=ListDelete(&L,j,&e); /* 删除第j个数据 */ if(i==ERROR) printf(\"删除第%d个数据失败\\n\",j); else printf(\"删除第%d个的元素值为：%d\\n\",j,e); } printf(\"依次输出L的元素：\"); ListTraverse(L); j=5; ListDelete(&L,j,&e); /* 删除第5个数据 */ printf(\"删除第%d个的元素值为：%d\\n\",j,e); printf(\"依次输出L的元素：\"); ListTraverse(L); //构造一个有10个数的Lb i=InitList(&Lb); for(j=6;j Java语言描述 package array; /** * 1) 数组的插入、删除、按照下标随机访问操作； * 2）数组中的数据是int类型的； * * Author: Zheng * modify: xing, Gsealy */ public class Array { //定义整型数据data保存数据 public int data[]; //定义数组长度 private int n; //定义中实际个数 private int count; //构造方法，定义数组大小 public Array(int capacity){ this.data = new int[capacity]; this.n = capacity; this.count=0;//一开始一个数都没有存所以为0 } //根据索引，找到数据中的元素并返回 public int find(int index){ if (index=count) return -1; return data[index]; } //插入元素:头部插入，尾部插入 public boolean insert(int index, int value){ //数组中无元素 //if (index == count && count == 0) { // data[index] = value; // ++count; // return true; //} // 数组空间已满 if (count == n) { System.out.println(\"没有可插入的位置\"); return false; } // 如果count还没满，那么就可以插入数据到数组中 // 位置不合法 if (index count ) { System.out.println(\"位置不合法\"); return false; } // 位置合法 for( int i = count; i > index; --i){ data[i] = data[i - 1]; } data[index] = value; ++count; return true; } //根据索引，删除数组中元素 public boolean delete(int index){ if (index=count) return false; //从删除位置开始，将后面的元素向前移动一位 for (int i=index+1; i Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-17 20:14:13 "},"LinkList.html":{"url":"LinkList.html","title":"03. 链表","keywords":"","body":"03.链表 空间换时间&时间换空间 空间换时间的设计思想：当内存空间充足的时候，为了追求代码更快的执行速度，就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。 时间换空间的设计思想：内存空间比较紧缺时，可以选择空间复杂度相对较低、但时间复杂度相对很高的算法或者数据结构，来节省内存空间。 缓存实际上就是利用了空间换时间的设计思想。如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。但如果我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。 总结: 对于执行较慢的程序，可以通过消耗更多的内存（空间换时间）来进行优化； 对于内存消耗过多的程序，可以通过消耗更多的时间（时间换空间）来降低内存的消耗。 链表的存储结构 数组需要一块连续的内存空间来存储，需要事先申请需要申请内存空间；而链表通过“指针”将一组零散的内存块串联起来使用，不会占用还未使用的内存空间。 三种最常见的链表结构 单链表 链表通过指针将一组零散的内存块串联在一起，内存块称为链表的“结点”。每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址，叫作后继指针 next。 上图中有两个特殊的结点，分别是第一个结点（头结点）和最后一个结点（尾结点）。 头结点用来记录链表的基地址，用它可以遍历得到整条链表。 尾结点指向一个空地址 NULL，表示这是链表上最后一个结点。 循环链表 循环链表跟单链表的区在尾结点指针是指向链表的头结点。 和单链表相比，循环链表的优点是从链尾到链头比较方便。 当要处理的数据具有环型结构特点时，采用循环链表实现代码会简洁很多。 双向链表 双向链表支持两个方向，每个结点同时有后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。 双向链表需要额外的两个空间来存储后继结点和前驱结点的地址，存储同样的数据，双向链表要比单链表占用更多的内存空间。优点是双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点。 Java 语言的LinkedHashMap 就用到了双向链表这种数据结构。 双向循环链表 三种基本操作 删除操作 从链表中删除一个数据有两种情况： 删除结点中“值等于某个给定值”的结点 删除给定指针指向的结点。 对于第一种情况，各种链表都需要从头结点开始遍历对比，直到找到值等于给定值的结点，然后再删除。 单纯的删除操作时间复杂度是 O(1)，但遍历查找对应的时间复杂度为 O(n)。链表操作的总时间复杂度为 O(n)。 对于第二种情况，删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，单链表还是要从头结点开始遍历链表，直到 p->next=q，说明 p 是 q 的前驱结点。 双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。 所以，单链表删除操作需要 O(n) 的时间复杂度，而双向链表需要 O(1) 的时间复杂度。 插入操作 如果希望在链表的某个指定结点前面插入一个结点，双向链表需要O(1) 时间复杂度； 单向链表需要 O(n) 的时间复杂度，因为单链表都需要从头结点开始遍历，直到找到前驱节点 查询操作 链表的随机访问第 k 个元素，必须根据指针一个结点一个结点地依次遍历，直到找到相应的结点。链表随机访问需要 O(n) 的时间复杂度。 对于一个有序链表，双向链表的按值查询的效率会比单链表高一些。记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，双向链表平均只需要查找一半的数据。 链表 VS 数组 数组和链表的时间复杂度： 时间复杂度 数组 链表 插入删除 O(n) O(1) 随机访问 O(1) O(n) 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足(out of memory)”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容。 Java 中的 ArrayList 容器的动态扩容，存在数据拷贝的操作，而数据拷贝的操作是非常耗时的。举一个稍微极端的例子。如果我们用 ArrayList 存储了了 1GB 大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，ArrayList 会申请一个 1.5GB 大小的存储空间，并且把原来那 1GB 的数据拷贝到新申请的空间上。 如果对内存的使用非常苛刻数组就更适合，因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。 对链表进行频繁的插入、删除操作，会导致频繁的内存申请和释放，容易造成内存碎片，对于 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。 几个写链表的代码技巧 技巧一:理解指针或引用的含义 C 语言有“指针”的概念； Java、Python的“引用”相当于C 语言的“指针”。 “指针”和“引用”都是存储所指对象的内存地址。 将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。 p->next=q 表示 p 结点中的 next 指针存储了 q 结点的内存地址。 p->next=p->next->next 表示 p 结点的 next 指针存储了 p 结点的下下一个结点的内存地址。 通俗的讲，当一个函数中传入的参数为指针变量时，不会像传入一个基本类型一样(如int float)只是传入一个变量的副本，指针的传递对其自身也有影响。 技巧二:警惕指针丢失和内存泄漏 写链表代码的时候，指针指来指去，一会儿就不知道指到哪里了。所以，我们在写的时候，一定注意不要弄丢了指针。 指针往往都是怎么弄丢的呢？拿单链表的插入操作为例来分析一下： 如图所示，我们希望在结点 a 和相邻的结点 b 之间插入结点 x，假设当前指针 p 指向结点 a。如果我们将代码实现变成下面这个样子，就会发生指针丢失和内存泄露。 p->next = x; // 将 p 的 next 指针指向 x 结点； x->next = p->next; // 将 x 的结点的 next 指针指向 b 结点； 初学者经常会在这儿犯错。p->next 指针在完成第一步操作之后，已经不再指向结点 b 了，而是指向结点 x。第 2 行代码相当于将 x 赋值给 x->next，自己指向自己。因此，整个链表也就断成了两半，从结点 b 往后的所有结点都无法访问到了。 代码执行顺序在指针中需要格外的注意，因为某一个节点不仅对其本身具有影响，对它的下一个节点元素的访问也是有影响的(指针的next域中存放一个指向下一个节点的指针),尤其是在单链表中，下一节点的访问必须依托上一节点的next访问，如果next域指向改变，那么就有可能导致链表断裂。 对于有些语言来说，比如 C 语言，内存管理是由程序员负责的，如果没有手动释放结点对应的内存空间，就会产生内存泄露。所以，我们插入结点时，一定要注意操作的顺序，要先将结点 x 的 next 指针指向结点 b，再把结点 a 的 next 指针指向结点 x，这样才不会丢失指针，导致内存泄漏。所以，对于刚刚的插入代码，我们只需要把第 1 行和第 2 行代码的顺序颠倒一下就可以了。 同理，删除链表结点时，也一定要记得手动释放内存空间，否则，也会出现内存泄漏的问题。当然，对于像 Java 这种虚拟机自动管理内存的编程语言来说，就不需要考虑这么多了。 技巧三:利用哨兵简化实现难度 对于单链表的插入和删除操作，如果我们在结点 p 后面插入一个新的结点，只需要下面两行代码就可以搞定。 new_node->next = p->next; p->next = new_node; 但是，当我们要向一个空链表中插入第一个结点，刚刚的逻辑就不能用了。我们需要进行下面这样的特殊处理，其中 head 表示链表的头结点。所以，从这段代码，我们可以发现，对于单链表的插入操作，第一个结点和其他结点的插入逻辑是不一样的。 if (head == null) { head = new_node; } 我们再来看单链表结点删除操作。如果要删除结点 p 的后继结点，我们只需要一行代码就可以搞定。 p->next = p->next->next； 但是，如果我们要删除链表中的最后一个结点，前面的删除代码就不 work 了。跟插入类似，我们也需要对于这种情况特殊处理。写成代码是这样子的： if (head->next == null) { head = null; } 针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。 head 表示头结点指针指向链表中的第一个结点，head=null 表示链表中没有结点了。 哨兵是为了解决“边界问题”的，不直接参与业务逻辑。如果我们引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫带头链表。相反，没有哨兵结点的链表就叫作不带头链表。 带头链表： 哨兵结点是不存储数据的。因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑了。 实际上，这种利用哨兵简化编程难度的技巧，在插入排序、归并排序、动态规划等代码都有用到。 示例1： // 在数组 a 中，查找 key，返回 key 所在的位置 // 其中，n 表示数组 a 的长度 int find(char* a, int n, char key) { // 边界条件处理，如果 a 为空，或者 n 示例2： // 在数组 a 中，查找 key，返回 key 所在的位置 // 其中，n 表示数组 a 的长度 // 我举 2 个例子，你可以拿例子走一下代码 // a = {4, 2, 3, 5, 9, 6} n=6 key = 7 // a = {4, 2, 3, 5, 9, 6} n=6 key = 6 int find(char* a, int n, char key) { if(a == null || n 两段代码中执行次数最多就是 while 循环那一部分。第二段代码中，通过一个哨兵 a[n-1] = key，成功省掉了一个比较语句 i 利用哨兵简化编码 哨兵可以理解为它可以减少特殊情况的判断，比如判空，比如判越界，比如减少链表插入删除中对空链表的判断，比如例子中对i越界的判断。 空与越界可以认为是小概率情况，所以代码每一次操作都走一遍判断，在大部分情况下都会是多余的。 哨兵的巧妙就是提前将这种情况去除，比如给一个哨兵结点，以及将key赋值给数组末元素，让数组遍历不用判断越界也可以因为相等停下来。比如例子中，我们为了不在每个循环中判断(i 使用哨兵的指导思想应该是将小概率需要的判断先提前扼杀，比如提前给他一个值让他不为null，或者提前预设值，或者多态的时候提前给个空实现，然后在每一次操作中不必再判断以增加效率。 技巧四:重点留意边界条件处理 软件开发中，代码在一些边界或者异常情况下，最容易产生 Bug。要实现没有 Bug 的链表代码，一定要检查边界条件是否考虑全面，以及代码在边界条件下是否能正确运行。 常用检查链表代码是否正确的边界条件有： 如果链表为空时，代码是否能正常工作？ 如果链表只包含一个结点时，代码是否能正常工作？ 如果链表只包含两个结点时，代码是否能正常工作？ 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？ 如果这些边界条件下都没有问题，那基本上可以认为没有问题了。 当然，边界条件不止针对不同的场景，可能还有特定的边界条件。 写任何代码时，一定要多想想，你的代码在运行的时候，可能会遇到哪些边界情况或者异常情况。遇到了应该如何应对，这样写出来的代码才够健壮！ 技巧五:举例画图，辅助思考 找一个具体的例子，把它画下面释放一些脑容量，留更多的给逻辑思考，这样就会感觉到思路清晰很多。比如往单链表中插入一个数据这样一个操作，可以把各种情况都举一个例子，画出插入前和插入后的链表变化，如图所示： 写完代码之后，也可以举几个例子，画在纸上，照着代码走一遍，很容易就能发现代码中的 Bug。 技巧六:多写多练，没有捷径 下面 5 个常见的链表操作。只要把这几个操作都能写熟练，不熟就多写几遍，之后再也不会害怕写链表代码。 单链表反转 链表中环的检测 两个有序的链表合并 删除链表倒数第 n 个结点 求链表的中间结点 约瑟夫环问题 回文字符串判断 这些等再开一页写吧~ 写链表代码是最考验逻辑思维能力的。因为，链表代码到处都是指针的操作、边界条件的处理，稍有不慎就容易产生 Bug。链表代码写得好坏，可以看出一个人写代码是否够细心，考虑问题是否全面，思维是否缜密。 链表的C实现 记录3个不好掌握的点 头结点与头指针的区别 LinkList的代表含义 函数中传入LinkList与 LinkList * 的区别 关于头指针，我个人是类比数组的概念，在数组中数组名的指针即为第一个元素的地址，同样的我们可以横向思考，这种方式也适用与链表。 Head指针为单链表的头指针，单链表L：L既是单链表的名字，也是其头指针。链表中的最后一个结点的指针域定义为空指针(NULL)。我们把指向第一个结点的指针称为头指针，那么每次访问链表时都可以从这个头指针依次遍历链表中的每个元素。 struct node first; struct node *head = &first; 那么什么是头结点呢？对照上图，我们看看带头结点的链表。 //不带头结点的单链表的初始化 void LinkedListInit1(LinkedList L) { L=NULL; } //带头结点的单链表的初始化 void LinkedListInit2(LinkedList L) { L=(LNode *)malloc(sizeof(LNode)); if(L==NULL) { printf(\"申请空间失败！\"); exit(0); } L->next=NULL; } 当默认没有头结点时候，L的是为空，但当我们申请了内存后L=(LNode *)malloc(sizeof(LNode)),L就默认有了一个头结点。 我稍微捋了捋，L是一个(LinkList)，他应当是一个指针，指向头一个结点，当没有头结点的时候，我们的头指针并没有指向，直到有一个元素添加了进来，那么有头结点的时候呢，我们的创建内存的同时，也给了头指针的一个指向，那么以后L代表的其实就是头结点(具体可以类比指针开始为 null 后来赋值给了一个&a 类似的操作)，从此以后L->next 代表的是第一个结点元素的地址。 #include struct node { int data; struct node *next; }; int main(void) { struct node *root, head, first, second; root = &head; root->data = 0; root->next = &first; first.data = 1; first.next = &second; second.data = 2; second.next = NULL; while (root) { printf(\"%d\\n\", root->data); root = root->next; } return 0; } 第二个问题， typedef struct QNode Qnode typedef struct QNode *QueuePtr 同样通过这样一个例子可以这样来理解 typedef struct int ElemType typedef struct int* ElemTypePtr 第一个是 定义新的整型变量 ElemType 第二个是 定义新的指向整型变量的指针 ElemTypePtr 可以简单理解为 ElemType = int ElemTypePtr = int* 同理在上面的结构体中 可以理解为 typedef struct QNode QNode typedef struct QNode* QueuePtr 于是 QNode 的对象都是结构体 QueuePtr 的对象都是结构体指针 最后是最后一个问题，对于LinkList L: L是指向定义的node结构体的指针,可以用->运算符来访问结构体成员,即L->elem,而(L)就是个Node型的结构体了,可以用点运算符访问该结构体成员,即(L).elem; 对于LinkList L:L是指向定义的Node结构体指针的指针,所以(L)是指向Node结构体的指针,可以用->运算符来访问结构体成员,即(L)->elem,当然,(*L)就是Node型结构体了,所以可以用点运算符来访问结构体成员,即(L).elem; 在链表操作中,我们常常要用链表变量作物函数的参数,这时,用LinkList L还是LinkList L就很值得考虑深究了,一个用不好,函数就会出现逻辑错误,其准则是: 如果函数会改变指针L的值,而你希望函数结束调用后保存L的值,那你就要用LinkList L,这样,向函数传递的就是指针的地址,结束调用后,自然就可以去改变指针的值; 而如果函数只会修改指针所指向的内容,而不会更改指针的值,那么用LinkList L就行了。 举个例子 void InitList(LinkList *L) { // 这个* 其实是解引用 转换为LinkList型的链表 可以使用'->'的方式来进行访问节点的值 // 这里初始化了一个头结点 哦 关于头结点的事情等会会讲 *L = (LinkList)malloc(sizeof(Node)); (*L)->next = NULL; } //初始化链表,函数调用完毕后,L会指向一个空的链表,即会改变指针的值,所以要用*L void InitList(LinkList *L) { *L = (LinkList)malloc(sizeof(Node)); (*L)->next = NULL; } //清空链表L,使L重新变为空链表,函数调用完后不会改变指针L的值,只会改变指针L所指向的内容(即L->next的值) void ClearList(LinkList L) { LinkList p; while(p = L->next) // 释放p节点 free(p); } C语言实现 当一个序列中只含有指向它的后继结点的链接时，就称该链表为单链表。 ​ 单链表的示意图如下： ​ Head指针为单链表的头指针，单链表L：L既是单链表的名字，也是其头指针。链表中的最后一个结点的指针域定义为空指针(NULL)。 单链表的定义： struct Node { ElemType data; struct Node *next; }; typedef struct Node LNode; typedef struct Node *LinkedList; 单链表有带头结点和不带头结点之分。 ​ 上图为没有头结点的单链表，下图为带有头结点的单链表： ​ 单链表的初始化，即建立一个空链表 //不带头结点的单链表的初始化 void LinkedListInit1(LinkedList L) { L=NULL; } //带头结点的单链表的初始化 void LinkedListInit2(LinkedList L) { L=(LNode *)malloc(sizeof(LNode)); if(L==NULL) { printf(\"申请空间失败！\"); exit(0); } L->next=NULL; } 单链表的求长操作 单链表的求表长操作需要设定当前指针p和一个计数器j，初始时p指向链表中的第一个结点，p每向下移动一个结点时，j就加1，直到到达p链表的尾部。带头结点的链表，链表长度不包括头结点。 //带头结点的单链表求表长 int LinkedListLength(LinkedList L) { LNode *p; //p需要声明为LNode类型 p=L->next; int j=0; while(p!=NULL) { j++; p=p->next; //将p向下移动一个结点 } return j; } 单链表获取第i个结点元素的操作 设定p为当前结点，初始时p指向链表的第一个结点，然后向下移动i，此时p所指向的元素就是需要查找的第i个结点元素。 //带头结点的单链表取元素操作 LinkedList LinkedListGetINode(LinkedList L, int i) { LNode *p; p=L->next; int j=1; while((p!=NULL)&&(jnext; j++; } return p; } 单链表的定位操作 查找元素e第一次出现的位置。从链表的第一个结点开始，判断当前结点的值是否等于e，等于则返回该结点的指针，否则继续向后查找，直至到达链表的最后。 //带头结点的单链表定位操作 LNode LinkedListLocateE(LinkedList L, ElemType e) { LNode *p; p=L->next; while((p!=NULL)&&(p->data!=e)) { p=p->next; } return p; } 单链表的插入操作 在结点p之前插入一个新的结点q:对于不带头结点的单链表，结点p的位置有所不同，插入操作有以下两种情况： 1)在链表的表头插入： (1)创建一个新的结点q。 (2)将此结点的数据域赋值为e，并将它的next指针指向第一个结点，即L。 (3)将L修改为指向新的结点q。 操作示意图如下： ​ 2)在链表的中间插入 (1)创建一个新的结点q。 (2)将此结点的数据域赋值为e，并将它的next指针指向p。 (3)查找到p的前驱结点pre。 (4)将pre的next指针指向新创建的结点q。 操作示意图如下： ​ //不带头结点的单链表的插入操作 void LinkedListInertQE1(LinkedList L, LinkedList p, ElemType e) { q=(LNode *)malloc(sizeof(LNode)); //创建一个新的结点q if(q==NULL) { printf(\"申请空间失败！\"); exit(0); } q->data=e; if(p==L) //在表头插入 { q->next=L; L=q; } else //在表的中间进行插入 { pre=L; while((pre!=NULL)&&(pre->next!=p)) //寻找p的前驱 pre=pre->next; q->next=pre->next; pre->next=q; } } //带头结点的单链表的插入操作 void LinkedListInertQE2(LinkedList L, LinkedList p, ElemType e) { q=(LNode *)malloc(sizeof(LNode)); //创建一个新的结点q if(q==NULL) { printf(\"申请空间失败！\"); exit(0); } q->data=e; //插入新的结点 pre=L; while((pre!=NULL)&&(pre->next!=p)) //寻找p的前驱 pre=pre->next; q->next=pre->next; pre->next=q; } 单链表的删除操作 删除链表中的某个元素e，如果e在链表中出现不止一次，将删除第一次出现的e，否则什么也不做。 用p找到元素e所在的结点： 1)p是链表中的第一个结点 (1)将L指向p->next。 (2)释放p。 示意图如下： ​ 2)p是链表中的其他结点 (1)找到p的前驱结点pre。 (2)将pre->next指向p->next。 (3)释放p。 示意图如下： ​ //不带头结点的单链表的删除操作 void LinkedListDeleteQE1(LinkedList L, LinkedList p, ElemType e) { pre=L; while((pre!=NULL)&&(pre->next->data!=e)) //查找元素e的前驱 pre=pre->next; p=pre->next; if(p!=NULL) //找到需要删除的结点 { if(p==L) //删除的是第一个结点 L=p->next; else //删除的是其他结点 pre->next=p->next; free(p); } } //带头结点的单链表的删除操作 void LinkedListDeleteQE2(LinkedList L, LinkedList p, ElemType e) { pre=L; while((pre!=NULL)&&(pre->next->data!=e)) //查找元素e的前驱 pre=pre->next; p=pre->next; if(p!=NULL) //找到需要删除的结点 { pre->next=p->next; free(p); } } 单链表的创建操作 单链表的创建方法有两种：头插法和尾插法。 头插法是将新增结点插入第一个结点之前，示意图如下： ​ 尾插法是将新增结点插入最后一个结点之后，示意图如下： ​ //用头插法创建带头结点的单链表 void LinkedListCreateHeadL(LinkedList L, ElemType a[n]) { L=(LNode *)malloc(sizeof(LNode)); if(L==NULL) { printf(\"申请空间失败！\"); exit(0); } L->next=NULL; for(i=0; idata=a[i]; p->next=L->next; L->next=p; } } //用尾插法创建带头结点的单链表 void LinkedListCreateTailL(LinkedList L, ElemType a[n]) { L=(LNode *)malloc(sizeof(LNode)); if(L==NULL) { printf(\"申请空间失败！\"); exit(0); } L->next=NULL; tail=L; //设置尾指针，方便插入 for(j=0; jdata=a[j]; p->next=NULL; tail->next=p; tail=p; } } 单链表的合并操作 首先设置3个指针pa、pb、pc, pa和pb分别指向链表La与Lb的当前待比较插入结点，pc指向链表Lc的最后一个结点。当pa->data≤pb->data时，将pa所指的结点插入到pc后面，否则就将pb所指的结点插入到pc后面。最后，当有一个表合并完，将另一个表剩余的结点全插入到pc。 //带头结点的单链表合并操作 void LinkedListMergeLaLb(LinkedList La, LinkedList Lb, LinkedList Lc) { pa=La->next; pb=Lb->next; Lc=La; //借用表La的头结点作为表Lc的头结点 pc=Lc; while((pa!=NULL)&&(pb!=NULL)) { if(pa->datadata) { pc->next=pa; pc=pa; pa=pa->next; } else { pc->next=pb; pc=pb; pb=pb->next; } } if(pa!=NULL) pc=pa->next; else pc=pb->next; free(pb); //将Lb的表头结点释放 } Java实现 package linkedlist; /** * 1）单链表的插入、删除、查找操作； * 2）链表中存储的是int类型的数据； * * Author：Zheng */ public class SinglyLinkedList { // 整了一个头结点 private Node head = null; // 根据值获得结点 返回链表中第一个与value相等的值 public Node findByValue(int value) { // 指针p现在为头结点 Node p = head; while (p != null && p.data != value) { p = p.next; } return p; } public Node findByIndex(int index) { Node p = head; int pos = 0; while (p != null && pos != index) { p = p.next; ++pos; } return p; } //无头结点 //表头部插入 //这种操作将于输入的顺序相反，逆序 public void insertToHead(int value) { Node newNode = new Node(value, null); insertToHead(newNode); } public void insertToHead(Node newNode) { if (head == null) { head = newNode; } else { newNode.next = head; head = newNode; } } //顺序插入 //链表尾部插入 public void insertTail(int value){ Node newNode = new Node(value, null); //空链表，可以插入新节点作为head，也可以不操作 if (head == null){ head = newNode; }else{ Node q = head; while(q.next != null){ q = q.next; } newNode.next = q.next; q.next = newNode; } } public void insertAfter(Node p, int value) { Node newNode = new Node(value, null); insertAfter(p, newNode); } public void insertAfter(Node p, Node newNode) { if (p == null) return; newNode.next = p.next; p.next = newNode; } public void insertBefore(Node p, int value) { Node newNode = new Node(value, null); insertBefore(p, newNode); } public void insertBefore(Node p, Node newNode) { if (p == null) return; if (head == p) { insertToHead(newNode); return; } Node q = head; while (q != null && q.next != p) { q = q.next; } if (q == null) { return; } newNode.next = p; q.next = newNode; } public void deleteByNode(Node p) { if (p == null || head == null) return; if (p == head) { head = head.next; return; } Node q = head; while (q != null && q.next != p) { q = q.next; } if (q == null) { return; } q.next = q.next.next; } public void deleteByValue(int value) { if (head == null) return; Node p = head; Node q = null; while (p != null && p.data != value) { q = p; p = p.next; } if (p == null) return; if (q == null) { head = head.next; } else { q.next = q.next.next; } // 可重复删除指定value的代码 /* if (head != null && head.data == value) { head = head.next; } Node pNode = head; while (pNode != null) { if (pNode.next.data == data) { pNode.next = pNode.next.next; continue; } pNode = pNode.next; } */ } public void printAll() { Node p = head; while (p != null) { System.out.print(p.data + \" \"); p = p.next; } System.out.println(); } //判断true or false public boolean TFResult(Node left, Node right){ Node l = left; Node r = right; boolean flag=true; System.out.println(\"left_:\"+l.data); System.out.println(\"right_:\"+r.data); while(l != null && r != null){ if (l.data == r.data){ l = l.next; r = r.next; continue; }else{ flag=false; break; } } System.out.println(\"什么结果\"); return flag; /* if (l==null && r==null){ System.out.println(\"什么结果\"); return true; }else{ return false; }*/ } //　判断是否为回文 public boolean palindrome(){ if (head == null){ return false; }else{ System.out.println(\"开始执行找到中间节点\"); Node p = head; Node q = head; if (p.next == null){ System.out.println(\"只有一个元素\"); return true; } while( q.next != null && q.next.next != null){ p = p.next; q = q.next.next; } System.out.println(\"中间节点\" + p.data); System.out.println(\"开始执行奇数节点的回文判断\"); Node leftLink = null; Node rightLink = null; if(q.next == null){ //　p 一定为整个链表的中点，且节点数目为奇数 rightLink = p.next; leftLink = inverseLinkList(p).next; System.out.println(\"左边第一个节点\"+leftLink.data); System.out.println(\"右边第一个节点\"+rightLink.data); }else{ //p q　均为中点 rightLink = p.next; leftLink = inverseLinkList(p); } return TFResult(leftLink, rightLink); } } //带结点的链表翻转 public Node inverseLinkList_head(Node p){ //　Head　为新建的一个头结点 Node Head = new Node(9999,null); // p　为原来整个链表的头结点,现在Head指向　整个链表 Head.next = p; /* 带头结点的链表翻转等价于 从第二个元素开始重新头插法建立链表 */ Node Cur = p.next; p.next = null; Node next = null; while(Cur != null){ next = Cur.next; Cur.next = Head.next; Head.next = Cur; System.out.println(\"first \" + Head.data); Cur = next; } //　返回左半部分的中点之前的那个节点 //　从此处开始同步像两边比较 return Head; } //无头结点的链表翻转 public Node inverseLinkList(Node p){ Node pre = null; Node r = head; System.out.println(\"z---\" + r.data); Node next= null; while(r !=p){ next = r.next; r.next = pre; pre = r; r = next; } r.next = pre; //　返回左半部分的中点之前的那个节点 //　从此处开始同步像两边比较 return r; } public static Node createNode(int value) { return new Node(value, null); } // 整了一个静态类 做链表 public static class Node { private int data; private Node next; public Node(int data, Node next) { this.data = data; this.next = next; } public int getData() { return data; } } public static void main(String[]args){ SinglyLinkedList link = new SinglyLinkedList(); System.out.println(\"hello\"); //int data[] = {1}; //int data[] = {1,2}; //int data[] = {1,2,3,1}; //int data[] = {1,2,5}; //int data[] = {1,2,2,1}; // int data[] = {1,2,5,2,1}; int data[] = {1,2,5,3,1}; for(int i =0; i Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-18 13:07:06 "},"递归.html":{"url":"递归.html","title":"04. 递归","keywords":"","body":"如何理解“递归” 递归是一种非常高效、简洁的编码技巧，不过递归代码也比较难写、难理解。编写递归代码的关键就是不要把自己绕进去，正确姿势是写出递推公式，找出终止条件，然后再翻译成递归代码。 不过递归代码也比较难写、难理解。编写递归代码的关键就是不要把自己绕进去，正确姿势是写出递推公式，找出终止条件，然后再翻译成递归代码。 递归代码虽然简洁高效，但是，递归代码也有很多弊端。比如，堆栈溢出、重复计算、函数调用耗时多、空间复杂度高等，所以，在编写递归代码的时候，一定要控制好这些副作用。 很多数据结构和算法的编码实现都要用到递归，比如 DFS 深度优先搜索、前中后序二叉树遍历等。 一个生活中用到递归的例子： 周末你带着女朋友去电影院看电影，女朋友问你，咱们现在坐在第几排啊？电影院里面太黑了，看不清，没法数，现在你怎么办？于是你就问前面一排的人他是第几排，你想只要在他的数字上加一，就知道自己在哪一排了。但是，前面的人也看不清啊，所以他也问他前面的人。就这样一排一排往前问，直到问到第一排的人，说我在第一排，然后再这样一排一排再把数字传回来。直到你前面的人告诉你他在哪一排，于是你就知道答案了。 这就是一个非常标准的递归求解问题的分解过程，去的过程叫“递”，回来的过程叫“归”。基本上，所有的递归问题都可以用递推公式来表示。这个例子，用递推公式将它表示出来就是这样的： f(n)=f(n-1)+1 其中，f(1)=1 f(n) 表示你想知道自己在哪一排，f(n-1) 表示前面一排所在的排数，f(1)=1 表示第一排的人知道自己在第一排。有了这个递推公式，就可以很轻松地将它改为递归代码，如下： int f(int n) { if (n == 1) return 1; return f(n-1) + 1; } 递归需要满足的三个条件 满足三个条件的问题可以用递归来解决： 1. 一个问题的解可以分解为几个子问题的解 子问题就是数据规模更小的问题。比如，前面讲的电影院的例子，你要知道，“自己在哪一排”的问题，可以分解为“前一排的人在哪一排”这样一个子问题。 2. 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样 比如电影院那个例子，求解“自己在哪一排”的思路，和前面一排人求解“自己在哪一排”的思路，是一模一样的。 3. 存在递归终止条件 把问题分解为子问题，把子问题再分解为子子问题，一层一层分解下去，不能存在无限循环，这就需要有终止条件。 还是电影院的例子，第一排的人不需要再继续询问任何人，就知道自己在哪一排，也就是 f(1)=1，这就是递归的终止条件。 如何编写递归代码？ 写递归代码最关键的是写出递推公式，找到终止条件。 假如这里有 n 个台阶，每次你可以跨 1 个台阶或者 2 个台阶，请问走这 n 个台阶有多少种走法？如果有 7 个台阶，你可以 2，2，2，1 这样子上去，也可以 1，2，1，1，2 这样子上去，总之走法有很多，那如何用编程求得总共有多少种走法呢？ 可以根据第一步的走法把所有走法分为两类，第一类是第一步走了 1 个台阶，另一类是第一步走了 2 个台阶。所以 n 个台阶的走法就等于先走 1 阶后n-1 个台阶的走法，加上先走 2 阶后n-2 个台阶的走法。用公式表示就是： f(n) = f(n-1)+f(n-2) 再来看终止条件: 当有一个台阶时，就不需要再继续递归，就只有一种走法。所以 f(1)=1。 再用 n=2，n=3 这样比较小的数试验一下这个递归终止条件是否足够： n=2 时，f(2)=f(1)+f(0)。如果递归终止条件只有一个 f(1)=1，那 f(2) 就无法求解了。所以除了 f(1)=1 这一个递归终止条件外，还要有 f(0)=1，表示走 0 个台阶有一种走法，不过这样子看起来又不符合正常的逻辑思维。所以可以把 f(2)=2 作为一种终止条件，表示走 2 个台阶，有两种走法，一步走完或者分两步来走。 所以，递归终止条件就是 f(1)=1，f(2)=2。这时再拿 n=3，n=4 来验证一下，这个终止条件是否足够并且正确。 把递归终止条件和刚刚得到的递推公式放到一起就是这样的： f(1) = 1; f(2) = 2; f(n) = f(n-1)+f(n-2) 有了这个公式，我们转化成递归代码就简单多了。最终的递归代码是这样的： int f(int n) { if (n == 1) return 1; if (n == 2) return 2; return f(n-1) + f(n-2); } 写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。 第二个例子，人脑几乎没办法把整个“递”和“归”的过程一步一步都想清楚。 正确的理解递归的思维方式： 如果一个问题 A 可以分解为若干子问题 B、C、D，先假设子问题 B、C、D 已经解决，在此基础上思考如何解决问题 A。只需要思考问题 A 与子问题 B、C、D 两层之间的关系即可，不要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样理解起来就简单多了。 因此，编写递归代码的关键是，只要遇到递归，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。 递归代码要警惕堆栈溢出 函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。 上面的讲的电影院的例子，如果将系统栈或者 JVM 堆栈大小设置为 1KB，在求解 f(19999) 时便会出现如下堆栈报错： Exception in thread \"main\" java.lang.StackOverflowErrorCopy to clipboardErrorCopied 那么，如何避免出现堆栈溢出呢？ 方法之一是在代码中限制递归调用的最大深度，递归调用超过一定深度（比如 1000）之后，就直接返回报错。 电影院那个例子，可以改造成下面这样子，就可以避免堆栈溢出了： // 全局变量，表示递归的深度。 int depth = 0; int f(int n) { ++depth； if (depth > 1000) throw exception; if (n == 1) return 1; return f(n-1) + 1; } 但这种做法并不能完全解决问题，因为最大允许的递归深度跟当前线程剩余的栈空间大小有关，事先无法计算。如果实时计算，代码过于复杂，就会影响代码的可读性。所以，如果最大深度比较小，比如 10、50，就可以用这种方法，否则这种方法并不实用。 递归代码要警惕重复计算 刚才第二个递归代码的例子把整个递归过程分解一下： 从图中，可以看到要计算 f(5)，需要先计算 f(4) 和 f(3)，而计算 f(4) 还需要计算 f(3)，因此，f(3) 就被计算了很多次，这就是重复计算问题。 为了避免重复计算，我们可以通过一个数据结构（比如散列表）来保存已经求解过的 f(k)。当递归调用到 f(k) 时，先看下是否已经求解过了。如果是，则直接从散列表中取值返回，不需要重复计算。 public int f(int n) { if (n == 1) return 1; if (n == 2) return 2; // hasSolvedList 可以理解成一个 Map，key 是 n，value 是 f(n) if (hasSolvedList.containsKey(n)) { return hasSovledList.get(n); } int ret = f(n-1) + f(n-2); hasSovledList.put(n, ret); return ret; } 在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积聚成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈中保存一次现场数据，所以在分析递归代码空间复杂度时，需要额外考虑这部分的开销，比如电影院递归代码，空间复杂度是 O(n)。 将递归代码改写为非递归代码 递归代码的表达力很强，写起来非常简洁，但是空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用会耗时较多等问题。所以，应当根据实际情况尽量把递归代码改写为非递归代码。 只看 f(x) =f(x-1)+1 这个递推公式。可以这样改写： int f(int n) { int ret = 1; for (int i = 2; i 第二个例子也可以改为非递归的实现： int f(int n) { if (n == 1) return 1; if (n == 2) return 2; int ret = 0; int pre = 2; int prepre = 1; for (int i = 3; i 那是不是所有的递归代码都可以改为这种迭代循环的非递归写法呢？ 因为递归本身就是借助栈来实现的，如果自己在内存堆上实现栈，手动模拟入栈、出栈过程，这样任何递归代码都可以改写成看上去不是递归代码的样子。但是这种思路实际上是将递归改为了“手动”递归，徒增了实现的复杂度。 斐波那契数列 斐波那契数列（Fibonacci sequence），又称黄金分割数列，指的是这样一个数列：0、1、1、2、3、5、8、13、21、34、……。 在数学上，费波那契数列是以递归的方法来定义： F(0)=0(n=0) F(1)=1(n=1) F(n)=F(n-1)+F(n-2) (n>=2，n∈N*) python实现： def fib(n): if n Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-21 00:01:19 "},"Stack.html":{"url":"Stack.html","title":"05. 栈","keywords":"","body":"理解栈 “栈”的基本结构 后进者先出，先进者后出，就是典型的“栈”结构。 从栈的操作特性上来看，栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。 从功能上来说，数组或链表可以替代栈，但特定的数据结构是对特定场景的抽象，数组或链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然也就更容易出错。 当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，就应该首选“栈”这种数据结构。 实现一个“栈” 栈主要包含两个操作，入栈和出栈，也就是在栈顶插入一个数据和从栈顶删除一个数据。 栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作顺序栈，用链表实现的栈，我们叫作链式栈。 C数组实现: #include \"stdio.h\" #include \"stdlib.h\" #include \"math.h\" #include \"time.h\" #define OK 1 #define ERROR 0 #define TRUE 1 #define FALSE 0 #define MAXSIZE 20 /* 存储空间初始分配量 */ typedef int Status; typedef int SElemType; /* SElemType类型根据实际情况而定，这里假设为int */ /* 顺序栈结构 */ typedef struct { SElemType data[MAXSIZE]; int top; /* 用于栈顶指针 */ }SqStack; Status visit(SElemType c) { printf(\"%d \",c); return OK; } /* 构造一个空栈S */ Status InitStack(SqStack *S) { /* S.data=(SElemType *)malloc(MAXSIZE*sizeof(SElemType)); */ S->top=-1; return OK; } /* 把S置为空栈 */ Status ClearStack(SqStack *S) { S->top=-1; return OK; } /* 若栈S为空栈，则返回TRUE，否则返回FALSE */ Status StackEmpty(SqStack S) { if (S.top==-1) return TRUE; else return FALSE; } /* 返回S的元素个数，即栈的长度 */ int StackLength(SqStack S) { return S.top+1; } /* 若栈不空，则用e返回S的栈顶元素，并返回OK；否则返回ERROR */ Status GetTop(SqStack S,SElemType *e) { if (S.top==-1) return ERROR; else *e=S.data[S.top]; return OK; } /* 插入元素e为新的栈顶元素 */ Status Push(SqStack *S,SElemType e) { if(S->top == MAXSIZE -1) /* 栈满 */ { return ERROR; } S->top++; /* 栈顶指针增加一 */ S->data[S->top]=e; /* 将新插入元素赋值给栈顶空间 */ return OK; } /* 若栈不空，则删除S的栈顶元素，用e返回其值，并返回OK；否则返回ERROR */ Status Pop(SqStack *S,SElemType *e) { if(S->top==-1) return ERROR; *e=S->data[S->top]; /* 将要删除的栈顶元素赋值给e */ S->top--; /* 栈顶指针减一 */ return OK; } /* 从栈底到栈顶依次对栈中每个元素显示 */ Status StackTraverse(SqStack S) { int i; i=0; while(i c链表实现 #include \"stdio.h\" #include \"stdlib.h\" #include \"io.h\" #include \"math.h\" #include \"time.h\" #define OK 1 #define ERROR 0 #define TRUE 1 #define FALSE 0 #define MAXSIZE 20 /* 存储空间初始分配量 */ typedef int Status; typedef int SElemType; /* SElemType类型根据实际情况而定，这里假设为int */ /* 链栈结构 */ typedef struct StackNode { SElemType data; struct StackNode *next; }StackNode,*LinkStackPtr; typedef struct { LinkStackPtr top; int count; }LinkStack; Status visit(SElemType c) { printf(\"%d \",c); return OK; } /* 构造一个空栈S */ Status InitStack(LinkStack *S) { S->top = (LinkStackPtr)malloc(sizeof(StackNode)); if(!S->top) return ERROR; S->top=NULL; S->count=0; return OK; } /* 把S置为空栈 */ Status ClearStack(LinkStack *S) { LinkStackPtr p,q; p=S->top; while(p) { q=p; p=p->next; free(q); } S->count=0; return OK; } /* 若栈S为空栈，则返回TRUE，否则返回FALSE */ Status StackEmpty(LinkStack S) { if (S.count==0) return TRUE; else return FALSE; } /* 返回S的元素个数，即栈的长度 */ int StackLength(LinkStack S) { return S.count; } /* 若栈不空，则用e返回S的栈顶元素，并返回OK；否则返回ERROR */ Status GetTop(LinkStack S,SElemType *e) { if (S.top==NULL) return ERROR; else *e=S.top->data; return OK; } /* 插入元素e为新的栈顶元素 */ Status Push(LinkStack *S,SElemType e) { LinkStackPtr s=(LinkStackPtr)malloc(sizeof(StackNode)); s->data=e; s->next=S->top; /* 把当前的栈顶元素赋值给新结点的直接后继，见图中① */ S->top=s; /* 将新的结点s赋值给栈顶指针，见图中② */ S->count++; return OK; } /* 若栈不空，则删除S的栈顶元素，用e返回其值，并返回OK；否则返回ERROR */ Status Pop(LinkStack *S,SElemType *e) { LinkStackPtr p; if(StackEmpty(*S)) return ERROR; *e=S->top->data; p=S->top; /* 将栈顶结点赋值给p，见图中③ */ S->top=S->top->next; /* 使得栈顶指针下移一位，指向后一结点，见图中④ */ free(p); /* 释放结点p */ S->count--; return OK; } Status StackTraverse(LinkStack S) { LinkStackPtr p; p=S.top; while(p) { visit(p->data); p=p->next; } printf(\"\\n\"); return OK; } int main() { int j; LinkStack s; int e; if(InitStack(&s)==OK) for(j=1;j java数组实现： // 基于数组实现的顺序栈 public class ArrayStack { private String[] items; // 数组 private int count; // 栈中元素个数 private int n; // 栈的大小 // 初始化数组，申请一个大小为 n 的数组空间 public ArrayStack(int n) { this.items = new String[n]; this.n = n; this.count = 0; } // 入栈操作 public boolean push(String item) { // 数组空间不够了，直接返回 false，入栈失败。 if (count == n) return false; // 将 item 放到下标为 count 的位置，并且 count 加一 items[count] = item; ++count; return true; } // 出栈操作 public String pop() { // 栈为空，则直接返回 null if (count == 0) return null; // 返回下标为 count-1 的数组元素，并且栈中元素个数 count 减一 String tmp = items[count-1]; --count; return tmp; } } java链表实现 /** * 基于链表实现的栈。 * * Author: Zheng */ public class StackBasedOnLinkedList { private Node top = null; public void push(int value) { Node newNode = new Node(value, null); // 判断是否栈空 if (top == null) { top = newNode; } else { newNode.next = top; top = newNode; } } /** * 我用-1表示栈中没有数据。 */ public int pop() { if (top == null) return -1; int value = top.data; top = top.next; return value; } public void printAll() { Node p = top; while (p != null) { System.out.print(p.data + \" \"); p = p.next; } System.out.println(); } private static class Node { private int data; private Node next; public Node(int data, Node next) { this.data = data; this.next = next; } public int getData() { return data; } } } 不管是顺序栈还是链式栈，存储数据只需要一个大小为 n 的存储空间。 在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度是 O(1)。 空间复杂度是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。 不管是顺序栈还是链式栈，入栈、出栈只涉及栈顶个别数据的操作，所以时间复杂度都是 O(1)。 支持动态扩容的顺序栈 上面基于数组实现的栈，当栈满之后，就无法再往栈里添加数据了。尽管链式栈的大小不受限，但要存储 next 指针，内存消耗相对较多。 要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中： 出栈的时间复杂度是 O(1)，因为出栈操作不会涉及内存的重新申请和数据的搬移。 对于入栈操作来说，最好情况时间复杂度是 O(1)，最坏情况时间复杂度是 O(n)。当栈中有空闲空间时，入栈操作的仅1次赋值操作。但当空间不够时，就需要重新申请内存和数据搬移。 对于平均情况下的时间复杂度，可以采用摊还分析法。 假设： 栈空间不够时，重新申请一个是原来大小两倍的数组； 只有入栈操作没有出栈操作； 入栈操作均为 simple-push 操作，时间复杂度为 O(1)。 如果当前栈大小为 K已满，入栈时就要重新申请 2 倍大小的内存，并且做 K 个数据的搬移操作，然后再入栈。但接下来的 K-1 次入栈操作都只需要一个 simple-push 操作就可以完成： 这 K 次入栈操作，总共涉及了 K 个数据的搬移，以及 K 次 simple-push 操作。将 K 个数据搬移均摊到 K 次入栈操作，那每个入栈操作只需要一个数据搬移和一个 simple-push 操作。以此类推，入栈操作的均摊时间复杂度就为 O(1)。 均摊时间复杂度一般都等于最好情况时间复杂度。因为在大部分情况下，入栈操作的时间复杂度 O 都是 O(1)，只有在个别时刻才会退化为 O(n)，所以把耗时多的入栈操作的时间均摊到其他入栈操作上，平均情况下的耗时就接近 O(1)。 栈在软件工程中的实际应用 函数调用栈 int main() { int a = 1; int ret = 0; int res = 0; ret = add(3, 5); res = a + ret; printf(\"%d\", res); reuturn 0; } int add(int x, int y) { int sum = 0; sum = x + y; return sum; } main() 函数调用了 add() 函数，获取计算结果，并且与临时变量 a 相加，最后打印 res 的值。 下图表示在执行到 add() 函数时，函数调用栈出栈、入栈的的情况。 栈实现表达式求值 编译器如何利用栈来实现表达式求值？比如：34+13*9+44-12/3。 需要两个栈来实现：一个栈保存操作数，另一个栈保存运算符。 从左向右遍历表达式，遇到数字就压入操作数栈； 遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。 下图是 3+5*8-6 这个表达式的计算过程： 栈实现括号匹配 借助栈来检查表达式中的括号是否匹配： 假设表达式中只包含三种括号，圆括号 ()、方括号 [] 和花括号{}，并且它们可以任意嵌套。比如，{[{}]}或 [{()}([])] 等都为合法格式，而{[}()] 或 [({)] 为不合法的格式。对于一个包含三种括号的表达式字符串，如何检查它是否合法呢？ \"(\"跟\")\"匹配，\"[\"跟\"]\"匹配，\"{\"跟\"}\"匹配 使用一个栈即可实现： 从左到右依次扫描字符串，遇到左括号则将其压入栈中； 当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。 当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。 实现浏览器的前进与后退功能 依次访问完一串页面 a-b-c 之后，点击浏览器的后退按钮，就可以查看之前浏览过的页面 b 和 a。后退到页面 a，点击前进按钮，就可以重新查看页面 b 和 c。但是，如果后退到页面 b 后，点击了新的页面 d，那就无法再通过前进、后退功能查看页面 c 了。如何实现这个功能呢？ 使用两个栈X 和 Y即可实现： 栈 X中的栈顶数据表示当前访问的页面 打开页面时将数据压入栈 X，并清空栈Y。 当点击后退按钮时，取出栈 X数据 并放入栈 Y中。 当点击前进按钮时，取出栈 Y 数据放入栈 X 中。 当栈 X 中仅剩1个数据时，那就说明没有页面可以继续后退浏览了。 当栈 Y 中没有数据，那就说明没有页面可以点击前进按钮浏览了。 流程示例：顺序查看了 a，b，c 三个页面，就依次把 a，b，c 压入栈X： 点击后退按钮，从页面 c 后退到页面 a 之后，就依次把 c 和 b 从栈 X 中弹出，并且依次放入到栈 Y： 又点击前进按钮回到 b 页面，就把 b 再从栈 Y 中出栈，放入栈 X 中： 通过页面 b 访问新页面 d，则将d放入X中，同时清空栈 Y ： 总之，后退时将页面从X移动到Y；前进则将页面从Y移动到X；访问新页面时，则将新页面压入X，并清空Y。 三种操作都是取X的栈顶元素显示。 /** * 使用前后栈实现浏览器的前进后退。 * * @author chinalwb */ public class SampleBrowser { public static void main(String[] args) { SampleBrowser browser = new SampleBrowser(); browser.open(\"http://www.baidu.com\"); browser.open(\"http://news.baidu.com/\"); browser.open(\"http://news.baidu.com/ent\"); browser.goBack(); browser.goBack(); browser.goForward(); browser.open(\"http://www.qq.com\"); browser.goForward(); browser.goBack(); browser.goForward(); browser.goBack(); browser.goBack(); browser.goBack(); browser.goBack(); browser.checkCurrentPage(); } private String currentPage; private LinkedListBasedStack backStack; private LinkedListBasedStack forwardStack; public SampleBrowser() { this.backStack = new LinkedListBasedStack(); this.forwardStack = new LinkedListBasedStack(); } public void open(String url) { if (this.currentPage != null) { this.backStack.push(this.currentPage); this.forwardStack.clear(); } showUrl(url, \"Open\"); } public boolean canGoBack() { return this.backStack.size() > 0; } public boolean canGoForward() { return this.forwardStack.size() > 0; } public String goBack() { if (this.canGoBack()) { this.forwardStack.push(this.currentPage); String backUrl = this.backStack.pop(); showUrl(backUrl, \"Back\"); return backUrl; } System.out.println(\"* Cannot go back, no pages behind.\"); return null; } public String goForward() { if (this.canGoForward()) { this.backStack.push(this.currentPage); String forwardUrl = this.forwardStack.pop(); showUrl(forwardUrl, \"Foward\"); return forwardUrl; } System.out.println(\"** Cannot go forward, no pages ahead.\"); return null; } public void showUrl(String url, String prefix) { this.currentPage = url; System.out.println(prefix + \" page == \" + url); } public void checkCurrentPage() { System.out.println(\"Current page is: \" + this.currentPage); } /** * A LinkedList based Stack implementation. */ public static class LinkedListBasedStack { private int size; private Node top; static Node createNode(String data, Node next) { return new Node(data, next); } public void clear() { this.top = null; this.size = 0; } public void push(String data) { Node node = createNode(data, this.top); this.top = node; this.size++; } public String pop() { Node popNode = this.top; if (popNode == null) { System.out.println(\"Stack is empty.\"); return null; } this.top = popNode.next; if (this.size > 0) { this.size--; } return popNode.data; } public String getTopData() { if (this.top == null) { return null; } return this.top.data; } public int size() { return this.size; } public void print() { System.out.println(\"Print stack:\"); Node currentNode = this.top; while (currentNode != null) { String data = currentNode.getData(); System.out.print(data + \"\\t\"); currentNode = currentNode.next; } System.out.println(); } public static class Node { private String data; private Node next; public Node(String data) { this(data, null); } public Node(String data, Node next) { this.data = data; this.next = next; } public void setData(String data) { this.data = data; } public String getData() { return this.data; } public void setNext(Node next) { this.next = next; } public Node getNext() { return this.next; } } } } 两个问题 1.函数调用除了用“栈”来保存临时变量以外还可以用其他数据结构吗？ 答： 其实，我们不一定非要用栈来保存临时变量，只不过如果这个函数调用符合后进先出的特性，用栈这种数据结构来实现，是最顺理成章的选择。 从调用函数进入被调用函数，对于数据来说，变化的是作用域。只要能保证每进入一个新的函数，都是一个新的作用域就可以。 要实现这个，用栈就非常方便。在进入被调用函数的时候，分配一段栈空间给这个函数的变量，在函数结束的时候，将栈顶复位，正好回到调用函数的作用域内。 2.JVM 内存管理中有个“堆栈”的概念。栈内存用来存储局部变量和方法调用，堆内存用来存储 Java 中的对象。JVM 里面的“栈”跟数据结构的栈有什么区别呢？ 答： 内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构。 JVM 的内存空间在逻辑上分为：代码区、静态数据区、动态数据区 代码区 存储方法体的二进制代码。 控制代码区执行代码的切换： 高级调度（作业调度） 中级调度（内存调度） 低级调度（进程调度） 静态数据区 存储全局变量、静态变量、常量，常量包括final修饰的常量和String常量 系统自动分配和回收。 动态数据区 栈区：存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。 堆区：new一个对象的引用或地址存储在栈区，指向该对象存储在堆区中的真实数据。 Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-18 14:42:24 "},"queue.html":{"url":"queue.html","title":"06. 队列","keywords":"","body":"队列的结构 可以把队列想象成排队买票，先来的先买，后来的人只能站末尾，不允许插队。 队列最大的特点就是先进先出，主要的两个操作是入队和出队。跟栈一样，它既可以用数组来实现，也可以用链表来实现。用数组实现的叫顺序队列，用链表实现的叫链式队列。特别是长得像一个环的循环队列。在数组实现队列的时候，会有数据搬移操作，要想解决数据搬移的问题，就需要循环数组实现的循环队列。 先进者先出，是典型的“队列”。 后进者先出，先进者后出，是典型的“栈”结构。 栈只支持入栈 push()和出栈 pop()两个操作。 队列只支持：入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。 队列跟栈一样也是一种操作受限的线性表数据结构。 循环队列、阻塞队列、并发队列等具有某些额外特性的队列，它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。 比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列； Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。 队列的实现 用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。 数组实现的顺序队列 java基于数组的实现： // 用数组实现的队列 public class ArrayQueue { // 数组：items，数组大小：n private String[] items; private int n = 0; // head 表示队头下标，tail 表示队尾下标 private int head = 0; private int tail = 0; // 申请一个大小为 capacity 的数组 public ArrayQueue(int capacity) { items = new String[capacity]; n = capacity; } // 入队 public boolean enqueue(String item) { // 如果 tail == n 表示队列已经满了 if (tail == n) return false; items[tail] = item; ++tail; return true; } // 出队 public String dequeue() { // 如果 head == tail 表示队列为空 if (head == tail) return null; // 为了让其他语言的同学看的更加明确，把 -- 操作放到单独一行来写了 String ret = items[head]; ++head; return ret; } } c语言数组: #include \"stdio.h\" #include \"stdlib.h\" #include \"math.h\" #include \"time.h\" #define OK 1 #define ERROR 0 #define TRUE 1 #define FALSE 0 #define MAXSIZE 20 /* 存储空间初始分配量 */ typedef int Status; typedef int QElemType; /* QElemType类型根据实际情况而定，这里假设为int */ /* 循环队列的顺序存储结构 */ typedef struct { QElemType data[MAXSIZE]; int front; /* 头指针 */ int rear; /* 尾指针，若队列不空，指向队列尾元素的下一个位置 */ }SqQueue; Status visit(QElemType c) { printf(\"%d \",c); return OK; } /* 初始化一个空队列Q */ Status InitQueue(SqQueue *Q) { Q->front=0; Q->rear=0; return OK; } /* 将Q清为空队列 */ Status ClearQueue(SqQueue *Q) { Q->front=Q->rear=0; return OK; } /* 若队列Q为空队列,则返回TRUE,否则返回FALSE */ Status QueueEmpty(SqQueue Q) { if(Q.front==Q.rear) /* 队列空的标志 */ return TRUE; else return FALSE; } /* 返回Q的元素个数，也就是队列的当前长度 */ int QueueLength(SqQueue Q) { return (Q.rear-Q.front+MAXSIZE)%MAXSIZE; } /* 若队列不空,则用e返回Q的队头元素,并返回OK,否则返回ERROR */ Status GetHead(SqQueue Q,QElemType *e) { if(Q.front==Q.rear) /* 队列空 */ return ERROR; *e=Q.data[Q.front]; return OK; } /* 若队列未满，则插入元素e为Q新的队尾元素 */ Status EnQueue(SqQueue *Q,QElemType e) { if ((Q->rear+1)%MAXSIZE == Q->front) /* 队列满的判断 */ return ERROR; Q->data[Q->rear]=e; /* 将元素e赋值给队尾 */ Q->rear=(Q->rear+1)%MAXSIZE;/* rear指针向后移一位置， */ /* 若到最后则转到数组头部 */ return OK; } /* 若队列不空，则删除Q中队头元素，用e返回其值 */ Status DeQueue(SqQueue *Q,QElemType *e) { if (Q->front == Q->rear) /* 队列空的判断 */ return ERROR; *e=Q->data[Q->front]; /* 将队头元素赋值给e */ Q->front=(Q->front+1)%MAXSIZE; /* front指针向后移一位置， */ /* 若到最后则转到数组头部 */ return OK; } /* 从队头到队尾依次对队列Q中每个元素输出 */ Status QueueTraverse(SqQueue Q) { int i; i=Q.front; while((i+Q.front)!=Q.rear) { visit(Q.data[i]); i=(i+1)%MAXSIZE; } printf(\"\\n\"); return OK; } int main() { Status j; int i=0,l; QElemType d; SqQueue Q; InitQueue(&Q); printf(\"初始化队列后，队列空否？%u(1:空 0:否)\\n\",QueueEmpty(Q)); printf(\"请输入整型队列元素(不超过%d个),-1为提前结束符: \",MAXSIZE-1); do { /* scanf(\"%d\",&d); */ d=i+100; if(d==-1) break; i++; EnQueue(&Q,d); }while(i0) printf(\"现在由队头删除%d个元素:\\n\",l-2); while(QueueLength(Q)>2) { DeQueue(&Q,&d); printf(\"删除的元素值为%d\\n\",d); } j=GetHead(Q,&d); if(j) printf(\"现在队头元素为: %d\\n\",d); ClearQueue(&Q); printf(\"清空队列后, 队列空否？%u(1:空 0:否)\\n\",QueueEmpty(Q)); return 0; } 队列需要两个指针：一个是 head 指针，指向队头；一个是 tail 指针，指向队尾。 当 a、b、c、d 依次入队之后，队列中的 head 指针指向下标为 0 的位置，tail 指针指向下标为 4 的位置。 调用两次出队操作之后，队列中 head 指针指向下标为 2 的位置，tail 指针仍然指向下标为 4 的位置。 随着不停地进行入队、出队操作，head 和 tail 都会持续往后移动。 当 tail 移动到最右边，即使数组中还有空闲空间，也无法继续往队列中添加数据了。这时只需要触发一次数据的搬移操作即可： // 入队操作，将 item 放入队尾 public boolean enqueue(String item) { // tail == n 表示队列末尾没有空间了 if (tail == n) { // tail ==n && head==0，表示整个队列都占满了 if (head == 0) return false; // 数据搬移 for (int i = head; i 上面的代码中，当队列的 tail 指针移动到数组的最右边后，如果有新的数据入队，就将 head 到 tail 之间的数据，整体搬移到数组中 0 到 tail-head 的位置。 这种实现思路中，出队入队操作的时间复杂度是 O(1) 链表实现的链式队列 基于链表的实现，需要head 和 tail 两个指针。分别指向链表的第一个和最后一个结点。 入队时，tail->next= new_node, tail = tail->next；出队时，head = head->next。 java实现代码： public class QueueBasedOnLinkedList { // 队列的队首和队尾 private Node head = null; private Node tail = null; // 入队 public void enqueue(String value) { if (tail == null) { Node newNode = new Node(value, null); head = newNode; tail = newNode; } else { tail.next = new Node(value, null); tail = tail.next; } } // 出队 public String dequeue() { if (head == null) return null; String value = head.data; head = head.next; if (head == null) { tail = null; } return value; } public void printAll() { Node p = head; while (p != null) { System.out.print(p.data + \" \"); p = p.next; } System.out.println(); } private static class Node { private String data; private Node next; public Node(String data, Node next) { this.data = data; this.next = next; } public String getData() { return data; } } } c语言链表实现 #include \"stdio.h\" #include \"stdlib.h\" #include \"math.h\" #include \"time.h\" #define OK 1 #define ERROR 0 #define TRUE 1 #define FALSE 0 #define MAXSIZE 20 /* 存储空间初始分配量 */ typedef int Status; typedef int SElemType; /* SElemType类型根据实际情况而定，这里假设为int */ /* 链栈结构 */ typedef struct StackNode { SElemType data; struct StackNode *next; }StackNode,*LinkStackPtr; typedef struct { LinkStackPtr top; int count; }LinkStack; Status visit(SElemType c) { printf(\"%d \",c); return OK; } /* 构造一个空栈S */ Status InitStack(LinkStack *S) { S->top = (LinkStackPtr)malloc(sizeof(StackNode)); if(!S->top) return ERROR; S->top=NULL; S->count=0; return OK; } /* 把S置为空栈 */ Status ClearStack(LinkStack *S) { LinkStackPtr p,q; p=S->top; while(p) { q=p; p=p->next; free(q); } S->count=0; return OK; } /* 若栈S为空栈，则返回TRUE，否则返回FALSE */ Status StackEmpty(LinkStack S) { if (S.count==0) return TRUE; else return FALSE; } /* 返回S的元素个数，即栈的长度 */ int StackLength(LinkStack S) { return S.count; } /* 若栈不空，则用e返回S的栈顶元素，并返回OK；否则返回ERROR */ Status GetTop(LinkStack S,SElemType *e) { if (S.top==NULL) return ERROR; else *e=S.top->data; return OK; } /* 插入元素e为新的栈顶元素 */ Status Push(LinkStack *S,SElemType e) { LinkStackPtr s=(LinkStackPtr)malloc(sizeof(StackNode)); s->data=e; s->next=S->top; /* 把当前的栈顶元素赋值给新结点的直接后继，见图中① */ S->top=s; /* 将新的结点s赋值给栈顶指针，见图中② */ S->count++; return OK; } /* 若栈不空，则删除S的栈顶元素，用e返回其值，并返回OK；否则返回ERROR */ Status Pop(LinkStack *S,SElemType *e) { LinkStackPtr p; if(StackEmpty(*S)) return ERROR; *e=S->top->data; p=S->top; /* 将栈顶结点赋值给p，见图中③ */ S->top=S->top->next; /* 使得栈顶指针下移一位，指向后一结点，见图中④ */ free(p); /* 释放结点p */ S->count--; return OK; } Status StackTraverse(LinkStack S) { LinkStackPtr p; p=S.top; while(p) { visit(p->data); p=p->next; } printf(\"\\n\"); return OK; } int main() { int j; LinkStack s; int e; if(InitStack(&s)==OK) for(j=1;j 循环数组实现的队列 上面用数组来实现队列的时候，在 tail==n 时，会有数据搬移操作，采用循环数组则不需要数据搬移操作。 原本数组是有头有尾的是一条直线，把它首尾相连扳成一个环： 图中这个队列的大小为 8，当前 head=4，tail=7。 当有一个新的元素 a 入队时，放入下标为 7 的位置， tail 并不更新为 8，而是到下标为 0 的位置。 当再有一个元素 b 入队时，将 b 放入下标为 0 的位置，然后 tail 加 1 更新为 1。 在 a，b 依次入队之后，循环队列中的元素就变成了下面的样子： 确定队空和队满的判定条件。 队列为空的判断条件是 head == tail。 如上图，显然队列满的判断条件是(tail+1)%n=head， 为了避免和队空的判断条件混淆，则必须牺牲一个数组的存储空间。 java实现代码： public class CircularQueue { // 数组：items，数组大小：n private String[] items; private int n = 0; // head 表示队头下标，tail 表示队尾下标 private int head = 0; private int tail = 0; // 申请一个大小为 capacity 的数组 public CircularQueue(int capacity) { items = new String[capacity]; n = capacity; } // 入队 public boolean enqueue(String item) { // 队列满了 if ((tail + 1) % n == head) return false; items[tail] = item; tail = (tail + 1) % n; return true; } // 出队 public String dequeue() { // 如果 head == tail 表示队列为空 if (head == tail) return null; String ret = items[head]; head = (head + 1) % n; return ret; } } 队列在实际开发中的应用 阻塞队列 阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。 使用阻塞队列，就可以轻松实现一个“生产者 - 消费者模型”！ 这种基于阻塞队列实现的“生产者 - 消费者模型”，可以有效地协调生产和消费的速度。当“生产者”生产数据的速度过快，“消费者”来不及消费时，存储数据的队列很快就会满了。这个时候，生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续“生产”。 还可以通过协调“生产者”和“消费者”的个数，来提高数据的处理效率。 可以多配置几个“消费者”，来应对一个“生产者”： 并发队列 在多线程情况下，会有多个线程同时操作队列，这个时候就会存在线程安全问题。 线程安全的队列叫作并发队列。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。 有限资源池 常见的有限资源池有线程池和数据库连接池。 CPU 资源是有限的，任务的处理速度与线程个数并不是线性正相关。相反，过多的线程反而会导致 CPU 频繁切换，处理性能下降。所以，线程池的大小一般都是综合考虑要处理任务的特点和硬件环境，来事先设置的。 当我们向固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是怎么实现的呢？ 线程池一般有两种处理策略： 非阻塞的处理方式，直接拒绝任务请求； 阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。 我们希望公平地处理每个排队的请求，先进者先服务，队列这种数据结构很适合来存储排队请求。 基于链表实现的队列，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。 基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。 队列设置太大会导致等待的请求太多，设置太小会导致无法充分利用系统资源、发挥最大性能。 对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。 思考题 1、你还知道有哪些场景中会用到队列的排队请求呢？ 答： 各种消息队列，例如Active MQ ,Rabbit MQ ,Rocket MQ ,Zero MQ 以及分布式消息队列Kafka等。 2、如何实现无锁并发队列？ 答： 使用 CAS 原子操作 + 循环数组的方式可以实现。 对于java语言，jdk提供了java.util.concurrent.atomic 包实现 CAS 原子操作 Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-18 15:40:23 "},"sort.html":{"url":"sort.html","title":"07. 排序","keywords":"","body":"排序算法 最常用的排序算法; ​ 冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。 按照时间复杂度可分为三类： 排序算法 时间复杂度 是否基于比较 冒泡、插入、选择 O(n^2)O(n2) Y 快排、归并 O(nlogn)O(nlogn) Y 桶、计数、基数 O(n)O(n) N 排序算法的三个分析指标 排序算法的执行效率 一般从这几个方面来衡量： 1. 最好情况、最坏情况、平均情况时间复杂度 要分别给出最好情况、最坏情况、平均情况下的时间复杂度，并说出最好、最坏时间复杂度对应的要排序的原始数据是什么样的。 区分这三种时间复杂度的目的： 为了方便对比，所以都做一下区分。 要排序的数据，有的接近有序，有的完全无序。我们需要知道排序算法在不同数据下的性能表现。 2. 时间复杂度的系数、常数 、低阶 时间复杂度反应的是数据规模 n 很大的时候的一个增长趋势，它会忽略系数、常数、低阶。 但排序的是 1000 以内规模很小的数据，对同阶时间复杂度的排序算法性能对比的时候，应当把系数、常数、低阶也考虑进来。 3. 比较次数和交换（或移动）次数 基于比较的排序算法的执行过程，会涉及元素比较大小和元素交换或移动两种操作。 在分析排序算法的执行效率的时候，应该把比较次数和交换（或移动）次数也考虑进去。 排序算法的内存消耗 法的内存消耗可以通过空间复杂度来衡量。 原地排序（Sorted in place）算法，是特指空间复杂度是 O(1) 的排序算法。 排序算法的稳定性 稳定性是指如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。 比如有一组数据 2，9，3，4，8，3，按照大小排序之后是 2，3，3，4，8，9。 这组数据里有两个 3。经过某种排序算法排序之后，如果两个 3 的前后顺序没有改变，那我们就把这种排序算法叫作稳定的排序算法；如果前后顺序发生变化，那对应的排序算法就叫作不稳定的排序算法。 稳定排序算法可以保持金额相同的两个对象，在排序之后的前后顺序不变 在实际软件开发中，往往要排序的是一组对象，需要按照对象的某个 key 来排序。 比如给电商交易系统中的“订单”排序。订单有两个属性，下单时间和订单金额。需要按照金额从小到大，如果金额相同则按照下单时间从早到晚，对订单数据排序。 这个问题借助稳定排序算法的解决思路是：先按照下单时间给订单排序，排序完成之后，再用稳定排序算法，按照订单金额重新排序。两遍排序之后，我们得到的订单数据就是按照金额从小到大排序，金额相同的订单按照下单时间从早到晚排序的。 第一次排序之后，所有的订单按照下单时间从早到晚有序了。在第二次排序中，用的是稳定的排序算法，相同金额的订单仍然保持下单时间从早到晚有序。 在实际开发中，我对这个问题的解决方案是，把订单金额和下单时间两个key作为一个自定义的key进行排序。 在实际开发中，我对这个问题的解决方案是，把订单金额和下单时间两个key作为一个自定义的key进行排序。 时间复杂度O(n^2)的三种排序算法 冒泡排序(Bubble Sort) 冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。 比如对一组数据 4,5,6,3,2,14,5,6,3,2,1从小到到大进行排序的，第一趟冒泡过程是： 经过一次冒泡操作之后，6 这个元素已经存储在正确的位置上。要想完成所有数据的排序，只要进行 6 次这样的冒泡操作就行了： 这个冒泡过程还可以优化。当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。比如下图给 6 个元素排序，只需要 4 次冒泡操作就可以了： 冒泡排序算法的原理比较容易理解，具体的代码我贴到下面，你可以结合着代码来看我前面讲的原理。 Java描述: // 冒泡排序，a 表示数组，n 表示数组大小 public void bubbleSort(int[] a, int n) { if (n a[j+1]) { // 交换 int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; flag = true; // 表示有数据交换 } } if (!flag) break; // 没有数据交换，提前退出 } } 有心的同学注意到了代码上有了一个flag，用来标示本次循环是否有元素进行了交换，但是在某些部分有序的数组中，可能依次比较是一个比较多余的操作，这就可能需要到前人的经验之谈。 举个例子如下图所示的数组，后面4个元素已经有序(当然，这种情况也具有较大的局限性)，我们对与这种在后面数组有比较大的提升，所以针对这种情况，我们可以根据上一次遍历确定了，最后更改元素的最大下标，让以后的循环后界限就不必去遍历，因为第一次都没改变元素，后面的遍历更不回更改了～ // 冒泡排序，a 表示数组，n 表示数组大小 public void bubbleSort(int[] a, int n) { if (n a[j+1]) { // 交换 int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; // 之前的是i-j-1 其实也是因为每次确定有一个都不会比较了 lastExchangeIndex = j; flag = true; // 表示有数据交换 } } if (!flag) break; // 没有数据交换，提前退出 } } 分析冒泡排序 第一，冒泡排序是原地排序算法吗？ 冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为 O(1)，是一个原地排序算法。 第二，冒泡排序是稳定的排序算法吗？ 在冒泡排序中，只有交换才可以改变两个元素的前后顺序。有相邻的两个元素大小相等的时候未做交换，相同大小的数据在排序前后不会改变顺序，所以冒泡排序是稳定的排序算法。 第三，冒泡排序的时间复杂度是多少？ 最好情况下，要排序的数据已经是有序的了，只需要进行一次冒泡操作，就可以结束了，所以最好情况时间复杂度是 O(n)O(n)。而最坏的情况是，要排序的数据刚好是倒序排列的，需要进行 n 次冒泡操作，所以最坏情况时间复杂度为 O(n^2)O(n2)。 对于包含 n 个数据的数组，这 n 个数据有 n! 种排列方式。不同的排列方式，冒泡排序执行的时间肯定是不同的。平均时间复杂度就是加权平均期望时间复杂度，如果用概率论方法定量分析冒泡平均时间复杂度，涉及的数学推理和计算就会很复杂。 “有序度”和“逆序度”分析平均时间复杂度 有序度是数组中具有有序关系的元素对的个数。表达式： 有序元素对：a[i] 比如2,4,3,1,5,62,4,3,1,5,6这组数据的有序度为11，因为有序对为11个，分别是： (2,4)\\quad(2,3)\\quad(2,5)\\quad(2,6) \\ (4,5)\\quad(4,6)\\quad(3,5)\\quad(3,6)\\ (1,5)\\quad(1,6)\\quad(5,6)(2,4)(2,3)(2,5)(2,6)(4,5)(4,6)(3,5)(3,6)(1,5)(1,6)(5,6) 对于一个倒序排列的数组，比如 6,5,4,3,2,16,5,4,3,2,1有序度是 0； 对于一个完全有序的数组，比如1,2,3,4,5,61,2,3,4,5,6有序度就是n(n-1)/2n∗(n−1)/2，也就是 15。这种完全有序的数组的有序度叫作*满有序度。 逆序度的定义正好跟有序度相反（默认从小到大为有序）： 逆序元素对：a[i] > a[j], 如果 i 逆序度 = 满有序度 - 有序度。 排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，就说明排序完成了。 比如数组 4,5,6,3,2,14,5,6,3,2,1有序元素对有 (4，5) (4，6) (5，6)，有序度是 3。n=6排序完成之后满有序度为 n*(n-1)/2=15。 冒泡排序包含两个操作原子，比较和交换。每交换一次，有序度就加 1。 不管算法怎么改进，交换次数总是确定的，即逆序度，也就是n(n-1)/2n∗(n−1)/2–*初始有序度。上图就是 15–3=12，要进行 12 次交换操作。 对于包含 n 个数据的数组进行冒泡排序，最坏情况下初始状态的有序度是 0，要进行 n(n-1)/2n∗(n−1)/2 次交换。最好情况下，初始状态的有序度是 n(n-1)/ 2n∗(n−1)/2，不需要进行交换。可以取个中间值 n(n-1)/4n∗(n*−1)/4，来表示初始有序度既不是很高也不是很低的平均情况。 平均情况下，需要 n(n-1)/4n∗(n−1)/4 次交换操作，比较操作肯定要比交换操作多，而复杂度的上限是 O(n^2 )O(n2)，所以平均情况下的时间复杂度就是 O(n^2 )O(n*2)。 这个平均时间复杂度推导过程其实并不严格，但是很多时候很实用，毕竟概率论的定量分析太复杂，不太好用。 插入排序(Insertion Sort) 就像玩牌一样，插入排序的算法也是一个类似的思想:维护一个有序区，把元素一个一个拆入到有序区的适当位置，知道虽有元素有序为止。 给定无序数组如下： 把数组的首元素5作为有序区，此时有序区只有这一个元素： 第一轮 让元素8和有序区的元素依次比较。 8>5，所以元素8和元素5无需交换。 此时有序区的元素增加到两个： 第二轮 让元素6和有序区的元素依次比较。 6 6>5，所以把元素6和元素5无需交换。 此时有序区的元素增加到三个： 第三轮 让元素3和有序区的元素依次比较。 3 3 3 此时有序区的元素增加到四个： 以此类推，插入排序一共会进行（数组长度-1）轮，每一轮的结果如下： 在遍历无序区元素与有序区元素里进行比较的时候，没有必要将需要比较的元素一次与有序区进行交换。而是通过暂存比较元素，与有序区比较，将有序区元素往后挪来插入数据。 举个例子，我们以第三轮为例子: 在第三轮操作中，我们需要让元素3逐个与有序区的元素进行比较和交换，与8交换、与6交换、与5交换，最终交换到有序区的第一个位置。 但是我们并不需要真的进行完整交换，只需把元素3暂存起来，再把有序区的元素从左向右逐一复制。 第一步，暂存元素3： 第二步，和前一个元素比较，由于3 第三步，和前一个元素比较，由于3 第四步，和前一个元素比较，由于3 第五步，也是最后一步，把暂存的元素3赋值到数组的首位： 显然，这样的优化方法减少了许多无谓的交换。 public class ShellSort { public static void sort(int[] array, int n) { // 希尔增量 n-1为数组的长度 int d = n; // 循环条件为 增量为1 即 两个相邻的元素进行比较 与插入排序相同 while (d > 1) { // 设置希尔增量 d = d / 3 + 1; // 看这个增量上可以分治成多少个数组 for (int x = 0; x = 0; j -= d) { // 无序区有有序区的最后一位进行比较 if (temp 选择排序 选择排序的思路是这样的：首先，找到数组中最小的元素，拎出来，将它和数组的第一个元素交换位置，第二步，在剩下的元素中继续寻找最小的元素，拎出来，和数组的第二个元素交换位置，如此循环，直到整个数组排序完成。 至于选大还是选小，这个都无所谓，你也可以每次选择最大的拎出来排，也可以每次选择最小的拎出来的排，只要你的排序的手段是这种方式，都叫选择排序。 我们还是以[ 8，2，5，9，7 ]这组数字做例子。 第一次选择，先找到数组中最小的数字 2 ，然后和第一个数字交换位置。（如果第一个数字就是最小值，那么自己和自己交换位置，也可以不做处理，就是一个 if 的事情） 第二次选择，由于数组第一个位置已经是有序的，所以只需要查找剩余位置，找到其中最小的数字5，然后和数组第二个位置的元素交换。 第三次选择，找到最小值 7 ，和第三个位置的元素交换位置。 第四次选择，找到最小值8，和第四个位置的元素交换位置。 最后一个到达了数组末尾，没有可对比的元素，结束选择。 如此整个数组就排序完成了。 // 选择排序，a表示数组，n表示数组大小 public void selectionSort(int[] a, int n) { if (n 分析选择排序 第一，选择排序是原地排序算法吗？ 第一，选择排序是原地排序算法吗？ 选择排序算法的运行并不需要额外的存储空间，所以空间复杂度是 O(1)，这是一个原地排序算法。 第二，选择排序是稳定的排序算法吗？ 选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样破坏了稳定性。是一种不稳定的排序算法。 比如 5，8，5，2，9 这样一组数据，使用选择排序算法来排序的话，第一次找到最小元素 2，与第一个 5 交换位置，那第一个 5 和中间的 5 顺序就变了，所以就不稳定了。 第三，选择排序的时间复杂度是多少？ 选择排序总是需要进行(n-1)+(n-2)+...+2+1=n(n-1)/2次比较，所以最好情况时间复杂度、最坏情况和平均情况时间复杂度都为 O(n^2 )O(n2)。 为什么插入排序比冒泡排序更受欢迎？ 插入排序和冒泡排序的时间复杂度相同都是 O(n^2 )*O*(*n*2)，都是原地排序算法，为什么插入排序比冒泡排序更受欢迎？ 冒泡排序和插入排序，元素交换的次数是一个固定值，是原始数据的逆序度。 但是，从代码实现上来看，冒泡排序需要 1 个复杂的数据交换操作，而插入排序只需要 1 个赋值操作。在java语言上冒泡排序的1个数据交换操作需要3步才能实现： 冒泡排序中数据的交换操作： if (a[j] > a[j+1]) { // 交换 int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; flag = true; } 插入排序中数据的移动操作： if (a[j] > value) { a[j+1] = a[j]; // 数据移动 } else { break; } 对同一个逆序度是 K 的数组进行排序。用冒泡排序，需要 K 次交换操作，每次需要 3 个赋值语句，所以交换操作总耗时就是 3*K 单位时间。而插入排序中数据移动操作只需要 K 个单位时间。 所以，理论上来说，冒泡排序相对插入排序一般要多消耗3倍的时间。 三种时间复杂度是 O(n^2)O(n2) 的排序算法小结 希尔排序 希尔排序与直接插入排序的关系 插入排序的平均时间复杂度是O（n^2）。这个排序算法并不复杂，但显然并不是一个高效的排序算法。 那么，怎样可以对插入排序算法做出优化呢？我们不妨从插入排序的两个特点入手： 1.在大多数元素已经有序的情况下，插入排序的工作量较小 这个结论很明显，如果一个数组大部分元素都有序，那么数组中的元素自然不需要频繁地进行比较和交换。 2.在元素数量较少的情况下，插入排序的工作量较小 这个结论更加显而易见，插入排序的工作量和n的平方成正比，如果n比较小，那么排序的工作量自然要小得多。 预处理 如何对原始数组进行预处理呢？聪明的科学家想到了一种分组排序的方法，以此对数组进行一定的“粗略调整”。 所谓分组，就是让元素两两一组，同组两个元素之间的跨度，都是数组总长度的一半，也就是跨度为4。 如图所示，元素5和元素9一组，元素8和元素2一组，元素6和元素1一组，元素3和元素7一组，一共4组。 接下来，我们让每组元素进行独立排序，排序方式用直接插入排序即可。由于每一组的元素数量很少，只有两个，所以插入排序的工作量很少。每组排序完成后的数组如下： 这样一来，仅仅经过几次简单的交换，数组整体的有序程度得到了显著提高，使得后续再进行直接插入排序的工作量大大减少。这种做法，可以理解为对原始数组的“粗略调整”。 但是这样还不算完，我们可以进一步缩小分组跨度，重复上述工作。把跨度缩小为原先的一半，也就是跨度为2，重新对元素进行分组： 如图所示，元素5，1，9，6一组，元素2，3，8，7一组，一共两组。 接下来，我们继续让每组元素进行独立排序，排序方式用直接插入排序即可。每组排序完成后的数组如下： 此时，数组的有序程度进一步提高，为后续将要进行的排序铺平了道路。 最后，我们把分组跨度进一步减小，让跨度为1，也就等同于做直接插入排序。经过之前的一系列粗略调整，直接插入排序的工作量减少了很多，排序结果如下： 让我们重新梳理一下分组排序的整个过程： 像这样逐步分组进行粗调，再进行直接插入排序的思想，就是希尔排序，根据该算法的发明者，计算机科学家Donald Shell的名字所命名。 上面示例中所使用的分组跨度（4，2，1），被称为希尔排序的增量，增量的选择可以有很多种，我们在示例中所用的逐步折半的增量方法，是Donald Shell在发明希尔排序时提出的一种朴素方法，被称为希尔增量。在算法中我们普遍使用(arr.lengh/3)+ 1来表示增量。 public static void sort(int[] arr) { int length = arr.length; //区间 int gap = 1; while (gap 0) { for (int i = gap; i = 0 && arr[j] > tmp) { arr[j + gap] = arr[j]; j -= gap; } arr[j + gap] = tmp; } gap = gap / 3; } } 时间复杂度为O(nlogn)的三种排序算法 归并排序和快速排序是时间复杂度为 O(nlogn) 的排序算法，这两种排序算法适合大规模的数据排序，比时间复杂度为 O(n^2)O(n2) 的排序算法要更常用。 归并排序和快速排序是两种稍微复杂的排序算法，它们用的都是分治的思想，代码都通过递归来实现，过程非常相似。理解归并排序的重点是理解递推公式和 merge() 合并函数。同理，理解快排的重点也是理解递推公式，还有 partition() 分区函数。 归并排序算法是一种在任何情况下时间复杂度都比较稳定的排序算法，这也使它存在致命的缺点，即归并排序不是原地排序算法，空间复杂度比较高，是 O(n)。正因为此，它也没有快排应用广泛。 快速排序算法虽然最坏情况下的时间复杂度是 O(n^2 )O(n2)，但是平均情况下时间复杂度都是 O(nlogn)O(nlogn)。不仅如此，快速排序算法时间复杂度退化到 O(n^2 )O(n2)的概率非常小，可以通过合理地选择 pivot 来避免这种情况。 归并排序 归并排序（Merge Sort）的核心思想，如果要排序一个数组，先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。 归并排序使用的就是分治思想。分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。 分治算法一般都是用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧。 归并排序和擂台赛，有什么相同和不同之处呢？让我们以下面这个数组来举例说明： 归并排序就像是组织一场元素之间的“比武大会”，这场比武大会分成两个阶段： 1.分组 假设集合一共有n个元素，算法将会对集合进行逐层的折半分组。 第一层分成两个大组，每组n/2个元素； 第二层分成4个小组，每组n/4个元素； 第三层分成8个更小的组，每组n/8个元素； ...... 一直到每组只有一个元素为止。 这样一来，整个数组就分成了一个个小小的“擂台”。 2.归并 既然分了组，接下来就要开始“比武”了。 归并排序和擂台赛有一个很大的不同，就是擂台赛只需要决定谁是老大，而并不关心谁做老二和老三；归并排序的要求复杂一些，需要确定每一个元素的排列位置。 因此，当每个小组内部比较出先后顺序以后，小组之间会展开进一步的比较和排序，合并成一个大组；大组之间继续比较和排序，再合并成更大的组......最终，所有元素合并成了一个有序的集合。 这个比较与合并的过程叫做归并，对应英文单词merge，这正是归并排序名字的由来。 重点: 如何把两个有序的小集合归并成一个有序的大集合呢？ 归并操作需要哪三个步骤呢？我们以两个长度为4的集合为例： 第一步，创建一个额外大集合用于存储归并结果，长度是两个小集合之和。（p1，p2，p是三个辅助指针，用于记录当前操作的位置） 第二步，从左到右逐一比较两个小集合中的元素，把较小的元素优先放入大集合。 由于1 由于2 由于3 由于5 由于6 此时左侧的小集合已经没有元素可用了。 这样一来，两个有序的小集合就归并成了一个有序的大集合。 public class MergeSort{ public static void mergeSort(int[] arr,int start,int end) { //设置递归终止条件 if(startarr[p2]){ tempArray[p++] = arr[p2++]; }else{ tempArray[p++] = arr[p1++]; } } // 证明p2已经全放到临时数组中 需要将p1剩下的放入 while(p1 第一，归并排序是稳定的排序算法吗？ 归并排序在合并的过程中，如果 A[p…m] 和 A[m+1…r] 之间有值相同的元素，可以先把 A[p…m] 中的元素放入 tmp 数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一个稳定的排序算法。 第二，归并排序的时间复杂度是多少？ 递归代码的时间复杂度可以写成递推公式。 如果定义求解问题 a 的时间是 T(a)，求解问题 b、c 的时间分别是 T(b) 和 T(c) 那就可以得到这样的递推关系式： T(a) = T(b) + T(c) + KCopy to clipboardErrorCopied 其中 K 等于将两个子问题 b、c 的结果合并成问题 a 的结果所消耗的时间。 假设对 n 个元素进行归并排序需要的时间是 T(n)，那分解成两个子数组排序的时间都是 T(n/2)。而merge() 函数合并两个有序子数组的时间复杂度是 O(n)。所以，归并排序的时间复杂度的计算公式就是： T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。 T(n) = 2*T(n/2) + n； n>1Copy to clipboardErrorCopied 进一步分解一下计算过程： T(n) = 2*T(n/2) + n = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n ...... = 2^k * T(n/2^k) + k * n ......Copy to clipboardErrorCopied 通过一步一步分解推导可以得到T(n) =2^kT( \\frac{n}{2^k})+knT(n)=2k∗T(2k**n)+k∗n。 当 T(\\frac{n}{2^k})=T(1)T(2k**n)=T(1) 时，也就是 \\frac{n}{2^k}=12k**n=1，得到 k=log_2nk=log2n 。 将 k 值代入上面的公式，得到 T(n)=Cn+nlog_2nT(n)=C∗n+n∗log2n。 用大 O 标记法来表示T(n) 就等于 O(nlogn)O(nlogn)。所以归并排序的时间复杂度是 O(nlogn)O(nlogn)。 从原理分析和代码来看，归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)O(nlogn)。 第三，归并排序的空间复杂度是多少？ 归并排序不是原地排序算法。归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)O(n)。 快速排序 快速排序算法（Quicksort），简称为“快排”。 同冒泡排序一样，快速排序也属于交换排序，通过元素之间的比较和交换位置来达到排序的目的。 不同的是，冒泡排序在每一轮只把一个元素冒泡到数列的一端，而快速排序在每一轮挑选一个基准元素，并让其他比它大的元素移动到数列一边，比它小的元素移动到数列的另一边，从而把数列拆解成了两个部分。 这种思路就叫做分治法。 每次把数列分成两部分，究竟有什么好处呢？ 假如给定8个元素的数列，一般情况下冒泡排序需要比较8轮，每轮把一个元素移动到数列一端，时间复杂度是O（n^2）。 而快速排序的流程是什么样子呢？ 如图所示，在分治法的思想下，原数列在每一轮被拆分成两部分，每一部分在下一轮又分别被拆分成两部分，直到不可再分为止。 这样一共需要多少轮呢？平均情况下需要logn轮，因此快速排序算法的平均时间复杂度是 O（nlogn）。 基准元素的选择 基准元素，英文pivot，用于在分治过程中以此为中心，把其他元素移动到基准元素的左右两边。 那么基准元素如何选择呢？ 最简单的方式是选择数列的第一个元素： 元素的移动 选定了基准元素以后，我们要做的就是把其他元素当中小于基准元素的都移动到基准元素一边，大于基准元素的都移动到基准元素另一边。 具体如何实现呢？有两种方法： 1.挖坑法 2.指针交换法 挖坑法进行元素互相交换的次数比较多，而且比较难理解，所以在实现上使用了指针交换法。 何谓指针交换法？我们来看一看详细过程。给定原始数列如下，要求从小到大排序： 开局和挖坑法相似，我们首先选定基准元素Pivot，并且设置两个指针left和right，指向数列的最左和最右两个元素： 接下来是第一次循环，从right指针开始，把指针所指向的元素和基准元素做比较。如果大于等于pivot，则指针向左移动；如果小于pivot，则right指针停止移动，切换到left指针。 在当前数列中，1 轮到left指针行动，把指针所指向的元素和基准元素做比较。如果小于等于pivot，则指针向右移动；如果大于pivot，则left指针停止移动。由于left一开始指向的是基准元素，判断肯定相等，所以left右移一位。 由于7 > 4，left指针在元素7的位置停下。这时候，我们让left和right指向的元素进行交换。 接下来，我们进入第二次循环，重新切换到right向左移动。right先移动到8，8>4，继续左移。由于2 切换到left，6>4，停止在6的位置。 元素6和2交换。 进入第三次循环，right移动到元素3停止，left移动到元素5停止。 元素5和3交换。 进入第四次循环，right移动到元素3停止，这时候请注意，left和right指针已经重合在了一起。 当left和right指针重合之时，我们让pivot元素和left与right重合点的元素进行交换。此时数列左边的元素都小于4，数列右边的元素都大于4，这一轮交换终告结束。 Java实现快速排序: public class QuickSort { public static void quickSort(int[] arr, int startIndex, int endIndex) { if (startIndex >= endIndex) { return; } // 得到基准元素位置 int pivotIndex = partition(arr, startIndex, endIndex); // 根据基准元素，分成两个部分递归 分治递归 quickSort(arr, startIndex, pivotIndex - 1); quickSort(arr, pivotIndex + 1, endIndex); } public static int partition(int[] arr, int startIndex, int endIndex) { // 将基准元素定位首位置 int pivot = arr[startIndex]; // 获取左右指针 // 其实取startIndex + 1 更好 因为必然第一个与自身相等 int left = startIndex; int right = endIndex; while (right != left) { // 从right开始遍历 需要看左右指针不合并 因为合并了就必然是最后一个放基准元素的值 while (left pivot) { // 满足的就继续 不满足就停止循环 right--; } // 开始left遍历 与right类似 while (left = left // 用左 右都一样 int temp = arr[left]; arr[left] = arr[startIndex]; arr[startIndex] = temp; // 返回边界 进行分治 return left; } public static void main(String[] args) { int[] arr = new int[] { 4, 7, 6, 5, 3, 2, 8, 1 }; quickSort(arr, 0, arr.length - 1); for (int i : arr) { System.out.print(i+\" \"); } } } c语言的实现与Java相似 就不专门写了 计数排序 计数排序是一种非基于比较的排序算法，我们之前介绍的各种排序算法几乎都是基于元素之间的比较来进行排序的，计数排序的时间复杂度为 O(n + m )，m 指的是数据量，说的简单点，计数排序算法的时间复杂度约等于 O(n)，快于任何比较型的排序算法。 桶排序 基数排序 基数排序是一种非比较型整数排序算法，其原理是将数据按位数切割成不同的数字，然后按每个位数分别比较。 假设说，我们要对 100 万个手机号码进行排序，应该选择什么排序算法呢？排的快的有归并、快排时间复杂度是 O(nlogn)，计数排序和桶排序虽然更快一些，但是手机号码位数是11位，那得需要多少桶？内存条表示不服。 这个时候，我们使用基数排序是最好的选择。 Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-29 10:56:28 "},"二分查找.html":{"url":"二分查找.html","title":"08. 二分查找","keywords":"","body":"二分查找 二分查找思想 二分查找（Binary Search）算法，也叫折半查找算法。 二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。 假设有 1000 条订单数据，已经按照订单金额从小到大排序，每个订单金额都不同，并且最小单位是元。现在想知道是否存在金额等于 19 元的订单。如果存在，则返回订单数据，如果不存在则返回 null。 利用二分思想，每次都与区间的中间数据比对大小，缩小查找区间的范围。下图中，low 和 high 表示待查找区间的下标，mid 表示待查找区间的中间元素下标。 二分查找的时间复杂度为O(logn) 二分查找的实现 最简单的情况就是有序数组中不存在重复元素， Java 代码循环实现： public int bsearch(int[] a, int n, int value) { int low = 0; int high = n - 1; while (low ow、high、mid 都是指数组下标，其中 low 和 high 表示当前查找的区间范围，初始 low=0， high=n-1。mid 表示 [low, high] 的中间位置。我们通过对比 a[mid] 与 value 的大小，来更新接下来要查找的区间范围，直到找到或者区间缩小为 0，就退出。 需要注意的点： 1.循环退出条件是 low 2.mid=(low+high)/2 这种写法，在 low 和 high 比较大时，两者之和可能会溢出。 改进的方法是将 mid 的计算方式写成 low+(high-low)/2，转化成位运算 low+((high-low)>>1)更佳。 3.写成 low=mid 或者 high=mid，可能会发生死循环。应当写成low=mid+1，high=mid-1。 二分查找的java递归实现： // 二分查找的递归实现 public int bsearch(int[] a, int n, int val) { return bsearchInternally(a, 0, n - 1, val); } private int bsearchInternally(int[] a, int low, int high, int value) { if (low > high) return -1; int mid = low + ((high - low) >> 1); if (a[mid] == value) { return mid; } else if (a[mid] 二分查找应用场景的局限性 1.二分查找依赖的是顺序表结构，即数组。 二分查找算法需要按照下标随机访问元素，所以不能用链表随机访问的时间复杂度是 O(n)。所以，如果数据使用链表存储，二分查找的时间复杂就会变得很高。 二分查找只能用在数据是通过顺序表来存储的数据结构上。如果你的数据是通过其他数据结构存储的，则无法应用二分查找。 2.二分查找要求数据必须是有序的，或者无序但没有频繁的插入和删除操作。 数据没有序，进行一次排序，多次二分查找。这样排序的成本可被均摊，二分查找的边际成本就会比较低。 但如果数据集合有频繁的插入和删除操作，要想用二分查找，要么每次插入、删除操作之后保证数据仍然有序，要么在每次二分查找之前都先进行排序。针对这种动态数据集合，无论哪种方法，维护有序的成本都是很高的。 所以，二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中。 3.数据量太小二分查找性能提升不大 但如果数据之间的比较操作非常耗时，比较次数的减少会大大提高性能，这个时候二分查找就比顺序遍历更有优势。 4.数据量太大不适合二分查找 只有数据量比较大的时候，二分查找的优势才会比较明显。 不过，这里有一个例外。如果数据之间的比较操作非常耗时，不管数据量大小，我都推荐使用二分查找。比如，数组中存储的都是长度超过 300 的字符串，如此长的两个字符串之间比对大小，就会非常耗时。我们需要尽可能地减少比较次数，而比较次数的减少会大大提高性能，这个时候二分查找就比顺序遍历更有优势。 二分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。比如有 1GB 大小的数据，用数组来存储，就需要 1GB 的连续内存空间。 “连续”意味着即便有 2GB 的内存空间剩余，但是如果这剩余的 2GB 内存空间都是零散的，没有连续的 1GB 大小的内存空间，那就无法申请一个 1GB 大小的数组。 二分查找的三种变体 变体一:查找最后一个值等于给定值的元素 public int bsearch(int[] a, int n, int value) { int low = 0; int high = n - 1; while (low > 1); if (a[mid] > value) { high = mid - 1; } else if (a[mid] 如果 a[mid] 这个元素已经是数组中的最后一个元素了，那它肯定是我们要找的； 如果 a[mid] 的后一个元素 a[mid+1] 不等于 value，那也说明 a[mid] 就是我们要找的最后一个值等于给定值的元素。 如果 a[mid] 后面的一个元素 a[mid+1] 也等于 value，那说明当前的这个 a[mid] 并不是最后一个值等于给定值的元素。我们就更新 low=mid+1，因为要找的元素肯定出现在 [mid+1, high] 之间。 变体二:查找第一个大于等于给定值的元素 public int bsearch(int[] a, int n, int value) { int low = 0; int high = n - 1; while (low > 1); if (a[mid] >= value) { if ((mid == 0) || (a[mid - 1] 如果 a[mid] 小于要查找的值 value，那要查找的值肯定在 [mid+1, high] 之间，更新 low=mid+1。 对于 a[mid] 大于等于给定值 value 的情况，如果 a[mid] 前面已经没有元素，或者前面一个元素 a[mid-1] 小于要查找的值 value，那 a[mid] 就是目标元素。 如果 a[mid-1] 也大于等于要查找的值 value，那说明要查找的元素在 [low, mid-1] 之间，所以，我们将 high 更新为 mid-1。 实体三: public int bsearch(int[] a, int n, int value) { int low = 0; int high = n - 1; while (low > 1); if (a[mid] > value) { high = mid - 1; } else { if ((mid == n - 1) || (a[mid + 1] > value)) return mid; else low = mid + 1; } } return -1; } Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-20 23:40:21 "},"跳表.html":{"url":"跳表.html","title":"09.跳表","keywords":"","body":"跳表=链表+多级索引 跳表使用空间换时间的设计思路，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 O(logn)。 跳表的空间复杂度是 O(n)。跳表的实现非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。跳表的代码比起红黑树来说，要简单、易读。 链表加多级索引的结构，就是跳表。 对于一个单链表，即便链表中存储的数据是有序的，如果要查找某个数据，也只能从头到尾遍历，时间复杂度是 O(n)。 对链表建立一级“索引”，每两个结点提取一个结点到上一级，把抽出来的那一级叫作索引或索引层。图中的 down 表示 down 指针，指向下一级结点。 这样就可以先在索引层遍历，然后通过索引层结点的 down 指针，下降到原始链表这一层，继续遍历。 比如要查找16，当在索引层遍历到13时，发现索引层下一个节点是17大于目标16，则可从13的down指针下降到原始链表继续遍历。这样只需要再遍历 2 个结点，就可以找到值等于 16 的这个结点了。原来查找 16，需要遍历 10 个结点，加入一层索引后只需要遍历 7 个结点。 加来一层索引之后，查找一个结点需要遍历的结点个数减少了，查找效率提高了。继续再加一级索引，在第一级索引的基础之上，每两个结点就抽出一个结点到第二级索引。现在再查找 16，只需要遍历 6 个结点了，需要遍历的结点数量又减少了。 下图是一个包含 64 个结点的链表，建立五级索引。 在五级索引的作用下，查找 62 只需要遍历 11 个结点。当链表的长度 n 比较大时，比如 1000、10000 的时候，在构建多级索引之后，查找效率的提升就会非常明显。 跳表的时间复杂度分析 一个链表里有 n 个结点，每两个结点会抽出一个结点作为上一级索引的结点，那第一级索引的结点个数大约就是 n/2，第二级索引的结点个数大约就是 n/4，第三级索引的结点个数大约就是 n/8，依次类推，也就是说，第 k 级索引的结点个数是第 k-1 级索引的结点个数的 1/2，那第 k级索引结点的个数就是 n/(2^k)*n*/(2*k*)。 假设索引有 h 级，最高级的索引有 2 个结点，则 n/(2^h)=2n/(2h)=2，即 h=log_2n-1h=log2n−1。加上原始链表这一层，整个跳表的高度就是 log_2nlog2n。在跳表中查询某个数据的时候，如果每一层都要遍历 m 个结点，那在跳表中查询一个数据的时间复杂度就是 O(mlogn)O(m∗log*n)。 按照每两个结点提取一个结点到上一级建立索引这种结构，每一级索引都最多只需要遍历 3 个结点，那么m=3. 假设要查找的数据是 x，在第 k 级索引中遍历到 y 结点之后，发现 x 大于 y，小于后面的结点 z，所以通过 y 的 down 指针，从第 k 级索引下降到第 k-1 级索引。在第 k-1 级索引中，y 和 z 之间只有 3 个结点（包含 y 和 z），所以在 K-1 级索引中最多只需要遍历 3 个结点，依次类推，每一级索引都最多只需要遍历 3 个结点。 所以在跳表中查询任意数据的时间复杂度就是 O(logn)。 跳表的空间复杂度分析 假设原始链表大小为 n，那第一级索引大约有 n/2 个结点，第二级索引大约有 n/4 个结点，以此类推，每上升一级就减少一半，直到剩下 2 个结点。每层索引的节点数为： \\frac{n}2,\\frac{n}4,\\frac{n}8,...,8,4,22n,4n,8n,...,8,4,2 这几级索引的结点总和就是 \\frac{n}2+\\frac{n}4+\\frac{n}8+...+8+4+2=n-22n+4n+8n+...+8+4+2=n−2。所以跳表的空间复杂度是 O(n)。 将包含 n 个结点的单链表构造成跳表，需要额外再用接近 n 个结点的存储空间。 如果每三个结点或五个结点，抽一个结点到上级索引: 那第一级索引需要大约 n/3 个结点，第二级索引需要大约 n/9 个结点。每往上一级，索引结点个数都除以 3。为了方便计算，假设最高一级的索引结点个数是 1。空间复杂度依然是 O(n)，但比每两个结点抽一个结点的索引构建方法，减少了一半的索引结点存储空间。 在实际的软件开发中，原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略了。 跳表动态的插入和删除 跳表插入、删除操作的时间复杂度是 O(logn)。 对于删除操作，如果这个结点在索引中也有出现，删除原始链表中的结点之后还要删除对应的索引。 查找要删除的结点的时候，一定要获取前驱结点（双向链表不需要考虑这个问题）。 跳表索引动态更新 不停地往跳表中插入数据时，如果不更新索引，就有可能出现某 2 个索引结点之间数据非常多的情况。极端情况下，跳表还会退化成单链表。 作为一种动态数据结构，需要某种手段来维护索引与原始链表大小之间的平衡： 如果链表中结点多了，索引结点就相应地增加一些，避免复杂度退化，以及查找、插入、删除操作性能下降。 往跳表中插入数据的时候，可以同时将这个数据插入到部分索引层中。通过一个随机函数，来决定将这个结点插入到哪几级索引中，比如随机函数生成了值 K，就将这个结点添加到第一级到第 K 级这 K 级索引中。 Redis 用跳表实现有序集合 Redis 中的有序集合是通过跳表来实现的，严格点讲，其实还用到了散列表。 Redis 中的有序集合支持的核心操作主要有： 插入一个数据； 删除一个数据； 查找一个数据； 按照区间查找数据（比如查找值在 [100, 356] 之间的数据）； 迭代输出有序序列。 其中，插入、删除、查找以及迭代输出有序序列这几个操作，红黑树也可以完成，时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。 对于按照区间查找数据这个操作，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。这样做非常高效。 跳表相对红黑树而言代码更容易实现，简单就意味着可读性好，不容易出错。还有，跳表更加灵活，它可以通过改变索引构建策略，有效平衡执行效率和内存消耗。 跳表的简易代码实现 public class SkipList { private static final float SKIPLIST_P = 0.5f; private static final int MAX_LEVEL = 16; private int levelCount = 1; private Node cls = new Node(); // 带头链表 public Node find(int value) { Node p = cls; for (int i = levelCount - 1; i >= 0; --i) { while (p.forwards[i] != null && p.forwards[i].data = 0; --i) { while (p.forwards[i] != null && p.forwards[i].data = 0; --i) { while (p.forwards[i] != null && p.forwards[i].data = 0; --i) { if (update[i].forwards[i] != null && update[i].forwards[i].data == value) { update[i].forwards[i] = update[i].forwards[i].forwards[i]; } } } while (levelCount>1&&cls.forwards[levelCount]==null){ levelCount--; } } // 理论来讲，一级索引中元素个数应该占原始数据的 50%，二级索引中元素个数占 25%，三级索引12.5% ，一直到最顶层。 // 因为这里每一层的晋升概率是 50%。对于每一个新插入的节点，都需要调用 randomLevel 生成一个合理的层数。 // 该 randomLevel 方法会随机生成 1~MAX_LEVEL 之间的数，且 ： // 50%的概率返回 1 // 25%的概率返回 2 // 12.5%的概率返回 3 ... private int randomLevel() { int level = 1; while (Math.random() Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-23 14:41:58 "},"散列表.html":{"url":"散列表.html","title":"10.散列表","keywords":"","body":"散列表 散列表来源于数组，它借助散列函数对数组这种数据结构进行扩展，利用的是数组支持按照下标随机访问元素的特性。散列表两个核心问题是散列函数设计和散列冲突解决。散列冲突有两种常用的解决方法，开放寻址法和链表法。散列函数设计的好坏决定了散列冲突的概率，也就决定散列表的性能。 散列表的英文叫“Hash Table”，也叫它“哈希表”或者“Hash 表”，散列表用的是数组支持按照下标随机访问数据的特性，是数组的一种扩展。 散列表利用了数组按照下标随机访问的时候时间复杂度是 O(1) 的特性。通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当按照键值查询元素时，用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。 散裂函数 散列函数，可以定义成hash(key)，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。 散列函数，顾名思义，它是一个函数。我们可以把它定义成hash(key)，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。 散列函数设计的三点基本要求： 散列函数计算得到的散列值是一个非负整数； 如果 key1 = key2，那 hash(key1) == hash(key2)； 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。 对于第一点，因为数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。 对于第二点，相同的 key，经过散列函数得到的散列值也应该是相同的。 对于第三点，几乎无法找到一个完美的无冲突的散列函数，即便像业界著名的MD5、SHA、CRC等哈希算法，也无法完全避免这种散列冲突。而且，因为数组的存储空间有限，也会加大散列冲突的概率。针对散列冲突问题，需要通过其他途径来解决。 解决散裂冲突问题的两种方法 常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining。 1. 开放寻址法 开放寻址法的核心思想是，如果出现了散列冲突，就重新探测一个空闲位置，将其插入。 探测新的位置的方法有线性探测（Linear Probing）、二次探测（Quadratic probing）和双重散列（Double hashing） 线性探测： 往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。 下图黄色的色块表示空闲位置，橙色的色块表示已经存储了数据。 图中散列表的大小为 10，在元素 x 插入散列表之前，已经 6 个元素插入到散列表中。x 经过 Hash 算法之后，被散列到位置下标为 7 的位置，但是这个位置已经有数据了，所以就产生了冲突。于是我顺序地往后一个一个找，遍历到尾部都没有找到空闲的位置，于是我们再从表头开始找，直到找到空闲位置 2，于是将其插入到这个位置。 在散列表中查找元素，会先通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。 使用线性探测法解决冲突的散列表，对于删除操作，会将被删除的元素特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。 2. 连表法 在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。 插入的时候只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)。当查找、删除一个元素时，同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。 查找或删除操作的时间复杂度跟链表的长度 k 成正比，即 O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。 Word的单词拼写检查功能是如何实现的？ Word 这种文本编辑器能自动识别错误的英文单词，用标红的方式提示“拼写错误”。Word 的这个单词拼写检查功能是如何实现的呢？ 解决思路： 常用的英文单词有 20 万个左右，假设单词的平均长度是 10 个字母，平均一个单词占用 10 个字节的内存空间，那 20 万英文单词大约占 2MB 的存储空间，就算放大 10 倍也就是 20MB。对于现在的计算机来说，这个大小完全可以放在内存里面。所以可以用散列表来存储整个英文单词词典。 当用户输入某个英文单词时，我们拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示。借助散列表这种数据结构，就可以轻松实现快速判断是否存在拼写错误。 散列表的设计 散列函数要尽可能让散列后的值随机且均匀分布，尽可能地减少散列冲突，即便冲突之后，分配到每个槽内的数据也比较均匀。除此之外，散列函数的设计也不能太复杂，太复杂就会太耗时间，也会影响散列表的性能。 关于散列冲突解决方法的选择，大部分情况下，链表法更加普适。还可以将链表改造成其他动态查找数据结构，比如红黑树，来避免散列表时间复杂度退化成 O(n)。对于小规模数据、装载因子不高的散列表，比较适合用开放寻址法。 对于动态散列表来说，随着数据的不断增加，散列表总会出现装载因子过高的情况，这个时候需要启动动态扩容。 工业级的散列表的特性： 支持快速的查询、插入、删除操作； 内存占用合理，不能浪费过多的内存空间； 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。 散列表的设计思路： 设计一个合适的散列函数； 定义装载因子阈值，并且设计动态扩容策略； 选择合适的散列冲突解决方法。 散列表的查询效率并不都是 O(1)，它跟散列函数、装载因子、散列冲突等都有关系。如果散列函数设计得不好，或者装载因子过高，都可能导致散列冲突发生的概率升高，查询效率下降。 在极端情况下，所有的数据经过散列函数之后，可能都散列到同一个槽里，查询的时间复杂度就从 O(1) 急剧退化为 O(n)。 设计良好的散列函数 散列函数设计的好坏，决定了散列表冲突的概率大小，也直接决定了散列表的性能。 首先，散列函数的设计不能太复杂。过于复杂的散列函数，势必会消耗很多计算时间，也就间接的影响到散列表的性能。其次，散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突，而且即便出现冲突，散列到每个槽里的数据也会比较平均，不会出现某个槽内数据特别多的情况。 需要综合考虑关键字的长度、特点、分布、还有散列表的大小等各种因素。 实现 Word 拼写检查功能的散列函数可以这样设计：将单词中每个字母的ASCll 码值“进位”相加，然后再跟散列表的大小求余、取模，作为散列值。 比如，英文单词 nice，我们转化出来的散列值就是下面这样： hash(\"nice\")=((\"n\" - \"a\") * 26*26*26 + (\"i\" - \"a\")*26*26 + (\"c\" - \"a\")*26+ (\"e\"-\"a\")) / 78978Copy to clipboardErrorCopied 散列函数的设计方法还有直接寻址法、平方取中法、折叠法、随机数法等，根据实际情况设计即可。 装载因子过大时需要进行动态扩容 装载因子的计算公式： 散列表的装载因子 = 填入表中的元素个数 / 散列表的长度 装载因子越大说明散列表中的元素越多，空闲位置越少，散列冲突的概率就越大。不仅插入数据的过程要多次寻址或者拉很长的链，查找的过程也会因此变得很慢。 对于动态散列表来说，数据集合是频繁变动的，事先无法预估将要加入的数据个数。随着数据慢慢加入，装载因子就会慢慢变大。当装载因子大到一定程度之后，散列冲突就会变得不可接受。 装载因子过大时，就需要进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。假设每次扩容都申请一个原来散列表大小两倍的空间。如果原来散列表的装载因子是 0.8，那经过扩容之后，新散列表的装载因子就下降为原来的一半，变成了 0.4。 针对散列表的扩容，数据搬移操作相对数组要复杂很多。散列表的大小变了，数据的存储位置也变了需要通过散列函数重新计算每个数据的存储位置。 下图中，21 这个元素原来存储在下标为 0 的位置，搬移到新的散列表中，存储在下标为 7 的位置。 插入一个数据，最好情况下，不需要扩容，最好时间复杂度是 O(1)。最坏情况下，启动扩容需要重新申请内存空间，重新计算哈希位置，并且搬移数据，时间复杂度是 O(n)。用摊还分析法，均摊情况下，时间复杂度接近最好情况，就是 O(1)。 对于动态散列表，随着数据的删除，散列表中的数据会越来越少，空闲空间会越来越多。如果对空间消耗非常敏感，可以在装载因子小于某个值之后，启动动态缩容。 装载因子阈值的设置要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。 均摊插入避免低效扩容 当装载因子已经到达阈值，需要先进行扩容，再插入数据。这个时候，插入数据就会变得很慢，甚至会无法接受。 为了解决一次性扩容耗时过多的情况，可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，只申请新空间，但并不将老的数据搬移到新散列表中。 当有新数据要插入时，将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样就没有了集中的一次性数据搬移，而是分摊到了每一次插入操作上。 对于查询操作，先从新散列表中查找，如果没有找到，再去老的散列表中查找。 通过这样均摊的方法，将一次性扩容的代价，均摊到多次插入操作中，就避免了一次性扩容耗时过多的情况。这种实现方式，任何情况下，插入一个数据的时间复杂度都是 O(1)。 两种散裂冲突的解决办法的应用场景 开放寻址法和链表法，这两种冲突解决办法在实际的软件开发中都非常常用。比如，Java 中 LinkedHashMap 就采用了链表法解决冲突，ThreadLocalMap 是通过线性探测的开放寻址法来解决冲突。 1. 开放寻址法 优点：散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度，序列化起来比较简单。 缺点： 删除数据的时候需要特殊标记已经删除掉的数据。 所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。 使用开放寻址法解决冲突的散列表，装载因子的上限不能太大。 相比链表法更浪费内存空间。 当数据量比较小、装载因子小的时候，适合采用开放寻址法。 链表法 优点： 对内存的利用率比开放寻址法要高，链表结点可以在需要的时候再创建。 对大装载因子的容忍度更高：开放寻址法只能适用装载因子小于 1 的情况。对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也只是是链表的长度变长了而已。 缺点： 链表要存储指针对于比较小的对象的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍。 链表中的结点是零散分布在内存中的，不是连续的，对 CPU 缓存不友好对于执行效率有一定的影响。 如果存储的是大对象，即存储的对象的大小远远大于一个指针的大小（4 个字节或者 8 个字节），那链表中指针的内存消耗在大对象面前可以忽略了。 链表法中的链表可以改造为跳表、红黑树等其他的动态数据结构，这样即便所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是 O(logn)。 基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表 Java中的HashMap 1. 初始大小 HashMap 默认的初始大小是 16，当然这个默认值是可以设置的，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高 HashMap 的性能。 2. 装载因子和动态扩容 最大装载因子默认是 0.75，当 HashMap 中元素个数超过 0.75*capacity（capacity 表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。 3.散列冲突解决方法 HashMap 底层采用链表法来解决冲突。 在 JDK1.8 版本中， HashMap 的链表长度默认超过 8时，链表就转换为红黑树。当红黑树结点个数少于 8 个的时，红黑树又会转化为链表。 4. 散列函数 散列函数的设计并不复杂，追求的是简单高效、分布均匀： int hash(Object key) { int h = key.hashCode()； return (h ^ (h >>> 16)) & (capitity -1); //capicity 表示散列表的大小 }Copy to clipboardErrorCopied 其中，hashCode() 返回的是 Java 对象的 hash code。比如 String 类型的对象的 hashCode() ： public int hashCode() { int var1 = this.hash; if(var1 == 0 && this.value.length > 0) { char[] var2 = this.value; for(int var3 = 0; var3 散列表+链表 散列表这种数据结构虽然支持非常高效的数据插入、删除、查找操作，但是散列表中的数据都是通过散列函数打乱之后无规律存储的。也就说，它无法支持按照某种顺序快速地遍历数据。如果希望按照顺序遍历散列表中的数据，那需要将散列表中的数据拷贝到数组中，然后排序，再遍历。 因为散列表是动态数据结构，不停地有数据的插入、删除，按顺序遍历散列表中的数据的时候，都需要先排序，效率很低。为了解决这个问题，可以将散列表和链表（或者跳表）结合在一起使用。 用链表来实现 LRU 缓存淘汰算法，时间复杂度是 O(n)，通过散列表可以将这个时间复杂度降低到 O(1)。 Redis 有序集合不仅使用了跳表，还用到了散列表。 LinkedHashMap也用到了散列表和链表两种数据结构。 散列表+双向链表实现LRU缓存 用链表实现的 LRU 缓存淘汰算法查找的时间复杂度是 O(n)，而将散列表和链表组合使用，可以将查找的时间复杂度降低到 O(1)。 一个缓存（cache）系统主要包含下面这几个操作： 添加一个数据； 删除一个数据； 查找一个数据。 这三个操作都要涉及“查找”操作，单纯采用链表时间复杂度是 O(n)，散列表+链表时间复杂度是 O(1)。 双向链表的每个结点包含存储数据的data和prev、next、hnext三个指针。 hnext是散列表的拉链指针，前驱prev和后继next是双向链表的串联指针。 查找一个数据：通过散列表的拉链指针可以很快地在缓存中找到一个数据。找到数据之后将它移动到双向链表的尾部。 删除一个数据：找到数据所在的结点，然后将结点删除。借助散列表可以在 O(1) 时间复杂度里找到要删除的结点。 添加一个数据：查看这个数据是否已经在缓存中。如果已经在其中将其移动到双向链表的尾部；如果不在其中，再看缓存有没有满。如果满了，则将双向链表头部的结点删除，然后再将数据放到链表的尾部；如果没有满，就直接将数据放到链表的尾部。 Redis有序集合 在Redis有序集合中，每个成员对象有两个重要的属性，key（键值）和score（分值）。可以同时通过key 和 score 来查找数据。 比如用户积分排行榜有这样一个功能：可以通过用户的 ID 来查找积分信息，也可以通过积分区间来查找用户 ID 或者姓名信息。这里包含 ID、姓名和积分的用户信息，就是成员对象，用户 ID 就是 key，积分就是 score。 Redis 有序集合的操作： 添加一个成员对象； 按照键值来删除一个成员对象； 按照键值来查找一个成员对象； 按照分值区间查找数据，比如查找积分在 [100, 356] 之间的成员对象； 按照分值从小到大排序成员变量； 如果仅仅按照分值将成员对象组织成跳表的结构，那按照键值来删除、查询成员对象就会很慢。 可以再按照键值构建一个散列表，这样按照 key 来删除、查找一个成员对象的时间复杂度就变成了 O(1)。 Java的LinkedHashMap LinkedHashMap 是通过散列表和链表组合在一起实现的。它不仅支持按照插入顺序遍历数据，还支持按照访问顺序来遍历数据。 LinkedHashMap 中的“Linked”相当于在HashMap的基础上加了一层双向链表。 比如: // 10 是初始大小，0.75 是装载因子，true 是表示按照访问时间排序 HashMap m = new LinkedHashMap<>(10, 0.75f, true); m.put(3, 11); m.put(1, 12); m.put(5, 23); m.put(2, 22); m.put(3, 26); m.get(5); for (Map.Entry e : m.entrySet()) { System.out.println(e.getKey()); } 这段代码打印的结果是 1，2，3，5。 每次调用 put() 函数，往 LinkedHashMap 中添加数据的时候，都会将数据添加到链表的尾部，在前四个操作完成之后： 再次将键值为 3 的数据放入到 LinkedHashMap 的时候，会先查找这个键值是否已经有了，然后，再将已经存在的 (3,11) 删除，并且将新的 (3,26) 放到链表的尾部： 当访问到 key 为 5 的数据的时候，将被访问到的数据移动到链表的尾部： 按照访问时间排序的 LinkedHashMap 本身就是一个支持 LRU 缓存淘汰策略的缓存系统。 2道思考题 1.散列表+链表，把双向链表改成单链表，还能否正常工作呢？为什么呢？ 答：可以正常工作，散列表+链表主要是查找、删除和添加三种操作，改成单链表后，只是相对需要增加一个变量记录前驱节点，照样可以在找到目标节点后很快的实现查找、删除和添加三种操作。 2.假设猎聘网有 10 万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这 10 万个猎头 ID 和积分信息，让它能够支持这样几个操作： 根据猎头的 ID 快速查找、删除、更新这个猎头的积分信息； 查找积分在某个区间的猎头 ID 列表； 查找按照积分从小到大排名在第 x 位到第 y 位之间的猎头 ID 列表。 答： 构建一个散列表，并在链表节点上增加用于构建跳表的指针，散列表根据猎头的 ID 计算hash值，跳表根据积分从小到大排序。 ID 在散列表中存储，可以根据ID在O(1)的时间复杂度内快速查找、删除、更新这个猎头的积分信息。 积分在跳表存储，可以做到 O(logn) 的时间复杂度定位积分区间的起点，然后在原始链表中顺序往后遍历到积分的终点就可以了。 对跳表进行改造，每个索引结点中加入一个 span 字段，记录这个索引结点到下一个索引结点的包含的链表结点的个数。这样就可以利用跳表索引，快速计算出排名在某个区间的猎头列表。 实际开发中，可以直接利用 Redis 的有序集合来完成这些需求。 Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-24 15:12:35 "},"哈希算法.html":{"url":"哈希算法.html","title":"11.哈希算法","keywords":"","body":"哈希算法 哈希算法是指将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。 要设计一个优秀的哈希算法需要满足的几点要求： 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）； 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同； 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小； 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。 哈希算法要处理的文本可能是各种各样的。比如，对于非常长的文本，如果哈希算法的计算时间很长，那就只能停留在理论研究的层面，很难应用到实际的软件开发中。比如，我们把今天一篇包含 4000 多个汉字的文章，用 MD5 计算哈希值，用不了 1ms 的时间。 哈希算法的应用 最常见的应用分别是安全加密、唯一标识、数据校验、散列函数。 在分布式系统中的应用有负载均衡、数据分片、分布式存储。 应用一:安全加密 最常用于加密的哈希算法是MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）、SHA（Secure Hash Algorithm，安全散列算法）、DES（Data Encryption Standard，数据加密标准）、AES（Advanced Encryption Standard，高级加密标准）。 为什么哈希算法无法做到零冲突？ 鸽巢原理（也叫抽屉原理）是说，如果有 10 个鸽巢，有 11 只鸽子，那肯定有 1 个鸽巢中的鸽子数量多于 1 个，换句话说就是，肯定有 2 只鸽子在 1 个鸽巢内。 哈希算法产生的哈希值的长度是固定且有限的。比如 MD5 的哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^{128}2128 个数据，但要哈希的数据是无穷的。基于鸽巢原理，如果对 2^{128}+12128+1 个数据求哈希值，就必然会存在哈希值相同的情况。当然，哈希值越长的哈希算法，散列冲突的概率越低。 2^128=340282366920938463463374607431768211456Copy to clipboardErrorCopied 但MD5有 2^{128}2128 个不同的哈希值，散列冲突的概率小于 \\frac{1}{2^{128}}21281，冲突的概率极低。 通过毫无规律的穷举的方法，找到跟一个 MD5 值相同的另一个数据，那耗费的时间是个天文数字。没有绝对安全的加密。越复杂、越难破解的加密算法，需要的计算时间也越长。比如 SHA-256 比 SHA-1 要更复杂、更安全，相应的计算时间就会比较长。 应用二: 唯一标识 如果要在海量的图库中，搜索一张图是否存在 ，比较笨的办法就是，拿要查找的图片的二进制码串与图库中所有图片的二进制码串一一比对。如果相同，则说明图片在图库中存在。 给每一个图片取一个唯一标识，即信息摘要。比如，从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。通过这个唯一标识来判定图片是否在图库中，这样就可以减少很多工作量。 如果还想继续提高效率，可以把每个图片的唯一标识，和相应的图片文件在图库中的路径信息，都存储在散列表中。当要查看某个图片是不是在图库中的时候，先通过哈希算法对这个图片取唯一标识，然后在散列表中查找是否存在这个唯一标识。 如果不存在，那就说明这个图片不在图库中；如果存在，再通过散列表中存储的文件路径，获取到这个已经存在的图片，跟现在要插入的图片做全量的比对，看是否完全一样。如果一样，就说明已经存在；如果不一样，说明两张图片尽管唯一标识相同，但是并不是相同的图片。 应用三：数据校验 BT 下载是基于 P2P 协议的，比如下载一个电影文件，BT 下载会从多个机器上并行下载一个 2GB 的电影，这个电影文件可能会被分割成很多文件块（比如可以分成 100 块，每块大约 20MB）。等所有的文件块都下载完成之后，再组装成一个完整的电影文件就行了。 但网络传输是不安全的，下载的文件块有可能是被宿主机器恶意修改过的，又或者下载过程中出现了错误，所以下载的文件块可能不是完整的。 种子文件保存了 100 个文件块的哈希值。当文件块下载完成之后，通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。 应用四:散列函数 散列函数也是哈希算法的一种应用，相对哈希算法的其他应用，散列函数对于散列算法冲突的要求要低很多。 散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。散列函数中用到的散列算法，更加关注散列后的值是否能平均分布。 另外，散列函数用的散列算法一般都比较简单，比较追求效率。 应用五:负载均衡 负载均衡算法有轮询、随机、加权轮询等。 一个会话粘滞（session sticky）的负载均衡算法是指在同一个客户端上一次会话中的所有请求都路由到同一个服务器上。 实现方法： 通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 应用六:数据分片 哈希算法还可以用于数据的分片： 1.假如1T 的日志文件，里面记录了用户的搜索关键词，想要快速统计出每个关键词被搜索的次数，该怎么做呢？ 问题：搜索日志很大，没办法放到一台机器的内存中；如果只用一台机器来处理这么巨大的数据，处理时间会很长。 具体解决的思路：为了提高处理的速度，用 n 台机器并行处理。从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值分配到指定的机器上。 哈希值相同的搜索关键词会被分配到同一个机器上，同一个搜索关键词会被分配到同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。 这个处理过程也是 MapReduce 的基本设计思想。 2. 如何快速判断图片是否在图库中（图库中有 1 亿张以上的海量图片）？ 基本方法，即给每个图片取唯一标识（或者信息摘要），然后构建散列表。 问题： 1 亿张图片构建散列表远远超过了单台机器的内存上限。 解决思路： 准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。每次从图库中读取一个图片，计算唯一标识与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。 当判断一个图片是否在图库中的时候，通过同样的哈希算法，计算这个图片的唯一标识与机器个数 n 求余取模。假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找。 给 1 亿张图片构建散列表所需存储空间估算： 散列表中每个数据单元包含两个信息，哈希值和图片文件的路径。假设通过 MD5 来计算哈希值，那长度就是 128 比特， 16 字节。文件路径长度的上限是 256 字节，可以假设平均长度是 128 字节。如果用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节。所以，散列表中平均每个数据单元就占用 152 字节。 假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表。所以对 1 亿张图片构建索引，大约需要十几台机器。 这种估算能事先对需要投入的资源、资金有个大概的了解，能更好地评估解决方案的可行性。 应用七:分布式存储 现在互联网面对的都是海量的数据、海量的用户，为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存。有海量的数据需要缓存，一个缓存机器肯定是不够的，就需要将数据分布在多台机器上。 随着数据增多就需要增加机器扩容了，但一旦扩容所有的数据都要重新计算哈希值，缓存中的数据一下子都失效了。 引入一致性哈希算法可以使得在新加入一个机器后，并不需要做大量的数据搬移。 一致性哈希算法 首先用哈希算法求出服务器（一般用ip地址或主机名）的哈希值与2^{32}232取模，将其映射到0～2^{32}0～232的Hash环上。 然后采用同样的哈希算法求出存储数据的键的哈希值与2^{32}232取模，映射到相同的Hash环上。 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。由于映射在环上，超过2^{32}232仍然找不到服务器就会指向第一台服务器。 当添加一台机器node5时，先计算hash值与2^{32}232取模并映射到Hash环上，然后将顺时针指向node5的数据从原本指向的node4迁移到node5机器上： 如果node5节点出现故障宕机，则数据分布又会重新恢复到上图的特点。 Hash环的偏斜 上面描述了比较理想的情况，但在实际的映射中，服务器可能会被映射成如下模样： 这样大部分缓存数据都被映射到了服务器A节点上。 虚拟节点 对于上面的情况，如果想要均衡地将缓存分布到三台服务器上，最佳办法是将现有的物理节点通过虚拟的方法复制出来映射到Hash环上，这些由实际节点虚拟复制而来的节点被称为\"虚拟节点\"。加入虚拟节点以后的hash环如下： \"虚拟节点\"是\"实际节点\"（实际的物理服务器）在hash环上的复制品，一个实际节点可以对应多个虚拟节点。上图中A、B、C三台服务器分别虚拟出了一个虚拟节点。实际可以虚拟出更多的虚拟节点，以便减小hash环偏斜所带来的影响，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大。 假设有4个物理节点Node，虚拟节点可设置为160个，此时可带来较好的均匀分布： “虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值： Hash(“192.168.1.100”); 引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值： Hash(“192.168.1.100#1”); // NODE1-1 Hash(“192.168.1.100#2”); // NODE1-2 哈希算法的其他应用 比如网络协议中的 CRC 校验、Git commit id 等等。 Hash算法在信息安全方面的应用主要体现在以下的3个方面： 1.文件校验 常见校验算法有奇偶校验和CRC校验，这2种校验并没有抗数据篡改的能力，它们一定程度上能检测并纠正数据传输中的信道误码，但却不能防止对数据的恶意破坏。 MD5 Hash算法的“数字指纹”特性，使它成为目前应用最广泛的一种文件完整性校验和（Checksum）算法，不少Unix系统有提供计算md5 checksum的命令。 2.数字签名 Hash 算法也是现代密码体系中的一个重要组成部分。由于非对称算法的运算速度较慢，所以在数字签名协议中，单向散列函数扮演了一个重要的角色。 对 Hash 值，又称“数字摘要”进行数字签名，在统计上可以认为与对文件本身进行数字签名是等效的。而且这样的协议还有其他的优点。 3.鉴权协议 鉴权协议又被称作挑战--认证模式：在传输信道是可被侦听，但不可被篡改的情况下，这是一种简单而安全的方法。 如何防止数据库中的用户信息被脱库? 引入一个盐（salt），跟用户的密码组合在一起，拿组合之后的字符串来做哈希算法加密，将它存储到数据库中。 不过安全和攻击是一种博弈关系，不存在绝对的安全。所有的安全措施，只是增加攻击的成本而已。 区块链&比特币 区块链是由包含交易信息的区块从后向前有序链接起来的数据结构. 它可以被存储为flat file (一种包含非相对关系记录的文件),或是存储在一个简单数据库中.比特币核心(Bitcoin Core)客户端使用Google的LeveLDB数据库存储区块链元数据.区块被从后向前有序地链接在这个链条里,每个区块都指向前一个区块. 区块链经常被视为一个垂直的栈,第一个区块作为栈底的首区块,随后每个区块都被放置在其他区块之上.用栈来形象化表示区块依次堆叠这一概念后, 我们便可以使用一些术语,例如,\"高度\"来表示区块与首区块之间的距离;以及用\"顶部\"或\"顶端\"来表示最新添加的区块. 对每个区块头进行SHA256加密哈希,可生成一个哈希值.通过这个哈希值, 可以识别出区块链中的对应区块.同时,每一个区块都可以通过其区块头的\"父区块哈希值\"字段引用前一区块(父区块).也就是说,每个区块头都包含它的父区块哈希值.这样把每个区块链接到各自父区块的哈希值序列就创建了一条一直可以追溯到第一区块(创世区块）的链条. 虽然每个区块都只有一个父区块,但可以暂时拥有多个子区块.每个子区块都将同一区块作为其父区块，并且在\"父区块哈希值\"字段中具有相同的(父区块)哈希值.一个区块出现多个子区块的情况被称为\"区块链分叉\".区块链分义只是暂时状态,只有当多个不同区块几乎同时被不同的矿工发现时才会发生. 最终,只有一个子区块会成为区块链的一部分,同时解决了\"区块链分叉\"的问题.尽管一个区块可能会有不止一个子区块,但每个区块只有一个父区块,这是因为一个区块只有一个\"父区块哈希值\"字段可以指向它的唯一父区块. 由于区块头里面包含\"父区块哈希值\"字段,所以当前区块的哈希值因此也受到该字段的影响.如果父区块的身份标识发生变化,子区块的身份标识也会跟看变化.当父区块有任何改动时,父区块的哈希值也发生变化。父区块的哈希值发生改变将迫使子区块的\"父区块哈希值\"字段发生改变,从而又将导致子区块的哈希值发生改变.而子区块的哈希值发生改变又将迫使孙区块的\"父区块哈希值”字段发生改变,又因此改变了孙区块哈希值,等等,以此类推.一旦一个区块自很多代以后,这种瀑布效应将保证该区块不会被改变,除非强制重新计算该区块所有后续的区块.正是因为这样的重新计算需要耗费巨大的计算量,所以一个长区块链的存在可以让区块链的历史不可改变，这也是比特巾安全性的一个关键特征. 区块结构 区块是一种被包含在公开账簿(区块链)里的聚合了交易信息的容器数据结构.它由一个包含元数据的区块头和紧跟其后的构成区块主体的一长串交易组成.区块头是80字节,而平均每个交易至少是250字节,而且平均每个区块至少包含超过500个交易.因此, 一个包含所有交易的元整区块比区块头的1000倍还要大.下表描述了一个区块结构. 区块头(区块中的B段) 区块头由三组区块元数据组成.首先是一组引用父区块哈希值的数据,这组元数据用于将该区块与区块链中前一区块相连接。第二组元数据 即难度、时间戳和Nonce,与挖矿竞争相关.第三组元数据是Merkle树根(一种用来有效地总结区块中所有交易的数据结构） 挖矿算法 比特币挖矿的算法，可以简单地总结为对区块头做两次sha256哈希运算，得到的结果如果小于区块头中规定的难度目标，即挖矿成功。 挖矿的流程可以定义为四个阶段： 验证和筛选交易 计算Merkle root 计算区块头 穷举nonce计算hash 验证和筛选交易 挖矿节点首先对交易做验证，剔除有问题的，然后通过一套自定义的标准来选择哪些交易希望打包进区块，比如通过交易费与交易占用的字节大小的比值超过某个门槛来判断，这样的交易才被认为有利可图。当然，节点也可以特意选择要加入某条交易，或者故意忽略某些交易，每个挖矿节点有很大的自由裁度权力。如果是通过矿池挖矿的话，矿池的服务器会去筛选交易，然后分配给每个参与的矿机一个独立的任务。这个任务的难度小于总的挖矿难度，通过完成较小难度的计算，来确认自己参与的份额。每台不同的矿机计算的问题不会重复，当其中一台矿机成功挖矿时，所有矿机依据确认的工作量来分配收益。 计算Merkle root 一旦筛选好交易数据，按照时间排序，两两哈希，层层约减，通过这些交易就可以计算出一棵Merkle树，可以确定一个唯一的摘要，这就是Merkl树的根。Merkle树中，任何节点的变化，都会导致merkle root发生变化，通过这个值，可以用来验证区块中的交易数据是否被改动过。 ABCDEEEE .......Merkle root / \\ ABCD EEEE / \\ / AB CD EE .......E与自己配对,奇数树叶时 / \\ / \\ / A B C D E .........交易 计算区块头 依次获取挖矿需要的每一项区块头信息。 区块头只有80个字节，挖矿只需要对区块头进行运算即可。区块头中的信息，在挖矿前大部分已经是固定的，或者是容易计算的。区块中的交易数据虽然很大，但是已经通过Merkle树固定了下来，不需要再包含进来。 逐项准备需要的数字： 版本号 跟随比特币客户端而定，一段时间内不会改变。即使要改变，也会有比特币的核心开发人员来协调升级策略，这个可以理解为一个静态常数。 前一区块摘要 一次哈希即可。前一区块已经是打包好的。 默克尔根 刚才已经得到了结果，根据本次交易包含的交易列表得到。 时间 取打包时的时间。也不需要很精确，前后几秒，几十秒也都可以。 难度目标 参考上两周产生的区块的平均生成时间而定。两周内如果平均10分钟产生一个区块的话，两周会产生2016个区块，软件会计算最新的2016个区块生成的时间，然后做对比，随之调整难度，使得接下来产生的区块的预期时间保持在10分钟左右。因为最近的2016个区块已经确定，所以这个数字也是确定的。 随机数nonce 这个就是挖矿的目标了。这是一个32位的数字。 穷举nonce计算hash 随机数可以变化，而且要从0试到最大值2^32。直到最后出现的hash结果，其数字低于难度目标值。不过以现在的计算机算力，一台矿机用不了一秒就把全部的变化可能计算完了，所以还需要改变区块内部的创币交易中的附带消息，这样就让merkle root也发生了变化，从而有更多的可能去找到符合要求的nonce。 挖矿中，第一笔交易是新发的比特币，接收方就是矿工指定的地址，这是挖矿中最大的奖励；另外一小部分来自交易手续费。这笔交易没有输入方，称为创币交易。 Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-24 15:32:34 "},"二叉树.html":{"url":"二叉树.html","title":"12.二叉树","keywords":"","body":"二叉树 树(Tree) 树是一种非线性表结构，比线性表的数据结构要复杂得多： 树的种类 树，二叉树 二叉查找树 平衡二叉查找树、红黑树 递归树 “树”的特征： “树”这种数据结构里面每个元素叫作“节点”；用来连线相邻节点之间的关系叫作“父子关系”。 比如下面这幅图，A 节点就是 B 节点的父节点，B 节点是 A 节点的子节点。B、C、D 这三个节点的父节点是同一个节点，所以它们之间互称为兄弟节点。没有父节点的节点叫根节点，也就是图中的节点 E。没有子节点的节点叫作叶子节点或者叶节点，比如图中的 G、H、I、J、K、L 都是叶子节点。 高度（Height）、深度（Depth）、层（Level）的定义： 节点的高度=节点到叶子节点的最长路径(边数) 节点的深度=根节点到这个节点所经历的边的个数 节点的层数=节点的深度+1 树的高度=根节点的高度Copy to clipboardErrorCopied “高度”是从下往上度量，从最底层开始计数计数的起点是 0。 “深度”是从上往下度量，从根结点开始度量计数起点也是 0。 “层数”跟深度的计算类似，不过计数起点是 1。 二叉树（Binary Tree） 二叉树的每个节点最多有两个子节点，分别是左子节点和右子节点。二叉树中，有两种比较特殊的树，分别是满二叉树和完全二叉树。满二叉树又是完全二叉树的一种特殊情况。 二叉树既可以用链式存储，也可以用数组顺序存储。数组顺序存储的方式比较适合完全二叉树，其他类型的二叉树用数组存储会比较浪费存储空间。除此之外，二叉树里非常重要的操作就是前、中、后序遍历操作，遍历的时间复杂度是 O(n)，需要用递归代码来实现。 二叉树是树的一种，特点是每个节点最多有两个子节点，分别是左子节点和右子节点。不过，二叉树有的节点只有左子节点，有的节点只有右子节点： 上图编号 2 的二叉树中，叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫作满二叉树。 编号 3 的二叉树中，叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫作完全二叉树。 二叉树存储 二叉树可以用哪些物理存储结构来表达呢？ 链式存储结构。 数组。 让我们分别看看二叉树如何使用这两种结构进行存储吧。 首先来看一看链式存储结构 。 链式存储是二叉树最直观的存储方式。 上一章讲过链表，链表是一对一的存储方式，每一个链表节点拥有data 变量和一个指向下一节点的next指针。 而二叉树稍微复杂一些，一个节点最多可以指向左右两个孩子节点，所 以二叉树的每一个节点包含3部分。 存储数据的data变量 指向左孩子的left指针 指向右孩子的right指针 再来看看用数组 是如何存储的。 使用数组存储时，会按照层级顺序把二叉树的节点放到数组中对应的位 置上。如果某一个节点的左孩子或右孩子空缺，则数组的相应位置也空 出来。 为什么这样设计呢？因为这样可以更方便地在数组中定位二叉树的孩子 节点和父节点。 假设一个父节点的下标是parent，那么它的左孩子节点下标就 是2×parent + 1 ；右孩子节点下标就是2×parent + 2 。 反过来，假设一个左孩子节点的下标是leftChild，那么它的父节点下标 就是（leftChild-1）/ 2 。 假如节点4在数组中的下标是3，节点4是节点2的左孩子，节点2的下标 可以直接通过计算得出。 节点2的下标 = (3-1)/2 = 1 显然，对于一个稀疏的二叉树来说，用数组表示法是非常浪费空间的。 什么样的二叉树最适合用数组表示呢？ 我们后面即将学到的二叉堆，一种特殊的完全二叉树，就是用数组来存 储的。 二叉树的应用 二叉树包含许多特殊的形式，每一种形式都有自己的作用，但是其最主 要的应用还在于进行查找操作和维持相对顺序 这两个方面。 查找 二叉树的树形结构使它很适合扮演索引的角色。 这里我们介绍一种特殊的二叉树：二叉查找树（binary search tree） 。 光看名字就可以知道，这种二叉树的主要作用就是进行查找操作。 二叉查找树在二叉树的基础上增加了以下几个条件。 如果左子树不为空，则左子树上所有节点的值均小于根节点的值 如果右子树不为空，则右子树上所有节点的值均大于根节点的值 左、右子树也都是二叉查找树 下图就是一个标准的二叉查找树。 二叉查找树的这些条件有什么用呢？当然是为了查找方便。 例如查找值为4的节点，步骤如下。 1. 访问根节点6，发现4 访问节点6的左孩子节点3，发现4>3。 访问节点3的右孩子节点4，发现4=4，这正是要查找的节点。 对于一个节点分布相对均衡 的二叉查找树来说，如果节点总数是n，那 么搜索节点的时间复杂度就是O(logn) ，和树的深度是一样的。 这种依靠比较大小来逐步查找的方式，和二分查找算法非常相似。 维持相对顺序 这一点仍然要从二叉查找树说起。二叉查找树要求左子树小于父节点， 右子树大于父节点，正是这样保证了二叉树的有序性。 因此二叉查找树还有另一个名字——二叉排序树（binary sort tree） 。 新插入的节点，同样要遵循二叉排序树的原则。例如插入新元素5，由 于53，5>4，所以5最终会插入到节点4的右孩子位置。 再如插入新元素10，由于10>6，10>8，10>9，所以10最终会插入到节点 9的右孩子位置。 这一切看起来很顺利，然而却隐藏着一个致命的问题。什么问题呢？下 面请试着在二叉查找树中依次插入9、8、7、6、5、4，看看会出现什么 结果。 二叉树的遍历 反观二叉树，是典型的非线性数据结构，遍历时需要把非线性关联的节 点转化成一个线性的序列，以不同的方式来遍历，遍历出的序列顺序也 不同。 那么，二叉树都有哪些遍历方式呢？ 从节点之间位置关系的角度来看，二叉树的遍历分为4种。 前序遍历。 中序遍历。 后序遍历。 层序遍历。 从更宏观的角度来看，二叉树的遍历归结为两大类。 1. 深度优先遍历 （前序遍历、中序遍历、后序遍历）。 广度优先遍历 （层序遍历）。 下面就来具体看一看这些不同的遍历方式。 深度优先遍历 深度优先和广度优先这两个概念不止局限于二叉树，它们更是一种抽象 的算法思想，决定了访问某些复杂数据结构的顺序。在访问树、图，或 其他一些复杂数据结构时，这两个概念常常被使用到。 所谓深度优先，顾名思义，就是偏向于纵深，“一头扎到底”的访问方 式。可能这种说法有些抽象，下面就通过二叉树的前序遍历、中序遍 历、后序遍历 ，来看一看深度优先是怎么回事吧。 前序遍历 二叉树的前序遍历，输出顺序是根节点、左子树、右子树。 上图就是一个二叉树的前序遍历，每个节点左侧的序号代表该节点的输 出顺序，详细步骤如下。 首先输出的是根节点1。 由于根节点1存在左孩子，输出左孩子节点2。 由于节点2也存在左孩子，输出左孩子节点4。 节点4既没有左孩子，也没有右孩子，那么回到节点2，输出节点2的 右孩子节点5。 节点5既没有左孩子，也没有右孩子，那么回到节点1，输出节点1的 右孩子节点3。 节点3没有左孩子，但是有右孩子，因此输出节点3的右孩子节点6。 到此为止，所有的节点都遍历输出完毕。 中序遍历 二叉树的中序遍历，输出顺序是左子树、根节点、右子树。 上图就是一个二叉树的中序遍历，每个节点左侧的序号代表该节点的输 出顺序，详细步骤如下。 首先访问根节点的左孩子，如果这个左孩子还拥有左孩子，则继续深 入访问下去，一直找到不再有左孩子的节点，并输出该节点。显然，第 一个没有左孩子的节点是节点4。 依照中序遍历的次序，接下来输出节点4的父节点2。 再输出节点2的右孩子节点5。 以节点2为根的左子树已经输出完毕，这时再输出整个二叉树的根节 点1。 由于节点3没有左孩子，所以直接输出根节点1的右孩子节点3。 最后输出节点3的右孩子节点6。 到此为止，所有的节点都遍历输出完毕。 后序遍历 二叉树的后序遍历，输出顺序是左子树、右子树、根节点。 上图就是一个二叉树的后序遍历，每个节点左侧的序号代表该节点的输 出顺序。 1. /** 2. * 构建二叉树 3. * @param inputList 4. */ 输入序列 5. public static TreeNode createBinaryTree(LinkedList inputList){ 6. TreeNode node = null; 7. if(inputList==null || inputList.isEmpty()){ 8. return null; 9. } 10. Integer data = inputList.removeFirst(); 11. if(data != null){ 12. node = new TreeNode(data); 13. node.leftChild = createBinaryTree(inputList); 14. node.rightChild = createBinaryTree(inputList); 15. } 16. return node; 17. } 18. 19. /** 20. * 二叉树前序遍历 21. * @param node 22. */ 二叉树节点 23. public static void preOrderTraveral(TreeNode node){ 24. 25. 26. 27. 28. 29. 30. } 31. 32. /** if(node == null){ return; } System.out.println(node.data); preOrderTraveral(node.leftChild); preOrderTraveral(node.rightChild); 33. * 二叉树中序遍历 34. * @param node 35. */ 二叉树节点 36. public static void inOrderTraveral(TreeNode node){ 37. if(node == null){ 38. return; 39. } 40. inOrderTraveral(node.leftChild); 41. System.out.println(node.data); 42. inOrderTraveral(node.rightChild); 43. } 44. 45. 46. /** 47. * 二叉树后序遍历 48. * @param node 49. */ 二叉树节点 50. public static void postOrderTraveral(TreeNode node){ 51. if(node == null){ 52. return; 53. } 54. postOrderTraveral(node.leftChild); 55. postOrderTraveral(node.rightChild); 56. System.out.println(node.data); 57. } 58. 59. 60. /** 61. * 二叉树节点 62. */ 63. private static class TreeNode { 64. int data; 65. TreeNode leftChild; 66. TreeNode rightChild; 67. 68. TreeNode(int data) { 69. this.data = data; 70. } 71. } 72. 73. public static void main(String[] args) { 74. LinkedList inputList = new LinkedList (Arrays. asList(new Integer[]{3,2,9,null,null,10,null, null,8,null,4})); 75. TreeNode treeNode = createBinaryTree(inputList); 76. System.out.println(\" 前序遍历：\"); 77. preOrderTraveral(treeNode); 78. System.out.println(\" 中序遍历：\"); 79. inOrderTraveral(treeNode); 80. System.out.println(\" 后序遍历：\"); 81. postOrderTraveral(treeNode); 82. } 广度优先遍历 如果说深度优先遍历是在一个方向上“一头扎到底”，那么广度优先遍历 则恰恰相反：先在各个方向上各走出1步，再在各个方向上走出第2步、 第3步……一直到各个方向全部走完。听起来有些抽象，下面让我们通 过二叉树的层序遍历 ，来看一看广度优先是怎么回事。 层序遍历，顾名思义，就是二叉树按照从根节点到叶子节点的层次关 系，一层一层横向遍历各个节点。 上图就是一个二叉树的层序遍历，每个节点左侧的序号代表该节点的输 出顺序。 可是，二叉树同一层次的节点之间是没有直接关联的，如何实现这种层 序遍历呢？ 这里同样需要借助一个数据结构来辅助工作，这个数据结构就是队列 。 详细遍历步骤如下。 根节点1进入队列。 节点1出队，输出节点1，并得到节点1的左孩子节点2、右孩子节点 3。让节点2和节点3入队。 节点2出队，输出节点2，并得到节点2的左孩子节点4、右孩子节点 5。让节点4和节点5入队。 节点3出队，输出节点3，并得到节点3的右孩子节点6。让节点6入 队。 节点4出队，输出节点4，由于节点4没有孩子节点，所以没有新节点 入队。 节点5出队，输出节点5，由于节点5同样没有孩子节点，所以没有新 节点入队。 节点6出队，输出节点6，节点6没有孩子节点，没有新节点入队。 到此为止，所有的节点都遍历输出完毕。 1. /** 2. * 二叉树层序遍历 3. * @param root 4. */ 二叉树根节点 5. public static void levelOrderTraversal(TreeNode root){ 6. Queue queue = new LinkedList(); 7. queue.offer(root); 8. while(!queue.isEmpty()){ 9. TreeNode node = queue.poll(); 10. System.out.println(node.data); 11. if(node.leftChild != null){ 12. queue.offer(node.leftChild); 13. } 14. if(node.rightChild != null){ 15. queue.offer(node.rightChild); 16. } 17. } 18. } Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-29 16:30:58 "},"二叉堆.html":{"url":"二叉堆.html","title":"14.二叉堆与优先队列","keywords":"","body":"二叉堆 堆是一种特殊的树: 堆是一个完全二叉树； 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。 堆必须是一个完全二叉树，除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列。 堆中的每个节点的值必须大于等于（或者小于等于）其子树中每个节点的值。 对于每个节点的值都大于等于子树中每个节点值的堆叫“大顶堆”。 对于每个节点的值都小于等于子树中每个节点值的堆叫“小顶堆”。 对于同一组数据可以构建多种不同形态的堆。 堆是一种完全二叉树。它最大的特性是：每个节点的值都大于等于（或小于等于）其子树节点的值。因此，堆被分成了两类，大顶堆和小顶堆。 下图中1、2是大顶堆，3是小顶堆，4不是堆。 二叉堆的自我调整 对于二叉堆，有如下几种操作。 插入节点。 删除节点。 构建二叉堆。 这几种操作都基于堆的自我调整。所谓堆的自我调整，就是把一个不符 合堆性质的完全二叉树，调整成一个堆。下面让我们以最小堆为例，看 一看二叉堆是如何进行自我调整的。 插入节点 当二叉堆插入节点时，插入位置是完全二叉树的最后一个位置。例如插 入一个新节点，值是 0。 这时，新节点的父节点5比0大，显然不符合最小堆的性质。于是让新节 点“上浮”，和父节点交换位置。 继续用节点0和父节点3做比较，因为0小于3，则让新节点继续“上浮”。 继续比较，最终新节点0“上浮”到了堆顶位置。 删除节点 二叉堆删除节点的过程和插入节点的过程正好相反，所删除的是处于堆 顶的节点。例如删除最小堆的堆顶节点1。 这时，为了继续维持完全二叉树的结构，我们把堆的最后一个节点10临 时补到原本堆顶的位置。 接下来，让暂处堆顶位置的节点10和它的左、右孩子进行比较，如果 左、右孩子节点中最小的一个（显然是节点2）比节点10小，那么让节 点10“下沉”。 继续让节点10和它的左、右孩子做比较，左、右孩子中最小的是节点 7，由于10大于7，让节点10继续“下沉”。 这样一来，二叉堆重新得到了调整。 构建二叉堆 构建二叉堆，也就是把一个无序的完全二叉树调整为二叉堆，本质就是 让所有非叶子节点依次“下沉” 。 下面举一个无序完全二叉树的例子，如下图所示。 首先，从最后一个非叶子节点开始，也就是从节点10开始。如果节点10 大于它左、右孩子节点中最小的一个，则节点10“下沉”。 接下来轮到节点3，如果节点3大于它左、右孩子节点中最小的一个，则 节点3“下沉”。 然后轮到节点1，如果节点1大于它左、右孩子节点中最小的一个，则节 点1“下沉”。事实上节点1小于它的左、右孩子，所以不用改变。 接下来轮到节点7，如果节点7大于它左、右孩子节点中最小的一个，则 节点7“下沉”。 节点7继续比较，继续“下沉”。 经过上述几轮比较和“下沉”操作，最终每一节点都小于它的左、右孩子 节点，一个无序的完全二叉树就被构建成了一个最小堆。 二叉堆的代码实现 在展示代码之前，我们还需要明确一点：二叉堆虽然是一个完全二叉 树，但它的存储方式并不是链式存储，而是顺序存储。换句话说，二叉 堆的所有节点都存储在数组中。 在数组中，在没有左、右指针的情况下，如何定位一个父节点的左孩子 和右孩子呢？ 像上图那样，可以依靠数组下标来计算。 假设父节点的下标是parent，那么它的左孩子下标就是 2×parent+1 ；右 孩子下标就是2×parent+2 。 例如上面的例子中，节点6包含9和10两个孩子节点，节点6在数组中的 下标是3，节点9在数组中的下标是7，节点10在数组中的下标是8。 1. /** 2. * “上浮”调整 3. * @param array 4. */ 待调整的堆 5. public static void upAdjust(int[] array) { 6. int childIndex = array.length-1; 7. int parentIndex = (childIndex-1)/2; 8. // temp 保存插入的叶子节点值，用于最后的赋值 9. int temp = array[childIndex]; 10. while (childIndex > 0 && temp =0; i--) { 54. downAdjust(array, i, array.length); 55. } 56. } 57. 58. public static void main(String[] args) { 59. int[] array = new int[] {1,3,2,6,5,7,8,9,10,0}; 60. upAdjust(array); 61. System.out.println(Arrays.toString(array)); 62. 63. array = new int[] {7,1,3,10,5,2,8,9,6}; 64. buildHeap(array); 65. System.out.println(Arrays.toString(array)); 66. } 代码中有一个优化的点，就是在父节点和孩子节点做连续交换时，并不 一定要真的交换，只需要先把交换一方的值存入temp变量，做单向覆 盖，循环结束后，再把temp的值存入交换后的最终位置即可。 优先队列 优先队列的特点 队列的特点是什么？ 在之前的章节中已经讲过，队列的特点是先进先出（FIFO） 。 入队列，将新元素置于队尾： 那么，优先队列又是什么样子呢？ 优先队列不再遵循先入先出的原则，而是分为两种情况。 最大优先队列，无论入队顺序如何，都是当前最大的元素优先出 队 最小优先队列，无论入队顺序如何，都是当前最小的元素优先出 队 例如有一个最大优先队列，其中的最大元素是8，那么虽然8并不是队头 元素，但出队时仍然让元素8首先出队。 优先队列的实现 先来回顾一下二叉堆的特性。 最大堆的堆顶是整个堆中的最大元素。 最小堆的堆顶是整个堆中的最小元素。 因此，可以用最大堆来实现最大优先队列，这样的话，每一次入队操作 就是堆的插入操作，每一次出队操作就是删除堆顶节点。 入队操作 具体步骤如下。 插入新节点5。 新节点5“上浮”到合适位置。 出队操作 具体步骤如下。 让原堆顶节点10出队。 把最后一个节点1替换到堆顶位置。 节点1“下沉”，节点9成为新堆顶。 1. private int[] array; 2. private int size; 3. public PriorityQueue(){ 4. //队列初始长度为32 5. array = new int[32]; 6. } 7. /** 8. * 入队 9. * @param key 入队元素 10. */ 11. public void enQueue(int key) { 12. 13. 14. 15. 16. 17. 18. } 19. 20. /** //队列长度超出范围，扩容 if(size >= array.length){ resize(); } array[size++] = key; upAdjust(); 21. * 出队 22. */ 23. public int deQueue() throws Exception { 24. if(size 0 && temp > array[parentIndex]) 43. { 44. //无须真正交换，单向赋值即可 45. array[childIndex] = array[parentIndex]; 46. childIndex = parentIndex; 47. parentIndex = parentIndex / 2; 48. } 49. array[childIndex] = temp; 50. } 51. /** 52. * “下沉”调整 53. */ 54. private void downAdjust() { 55. // temp 保存父节点的值，用于最后的赋值 56. int parentIndex = 0; 57. int temp = array[parentIndex]; 58. int childIndex = 1; 59. while (childIndex array[childIndex]) { childIndex++; } // 如果父节点大于任何一个孩子的值，直接跳出 if (temp >= array[childIndex]) break; //无须真正交换，单向赋值即可 array[parentIndex] = array[childIndex]; parentIndex = childIndex; childIndex = 2 * childIndex + 1; } array[parentIndex] = temp; 76. * 队列扩容 77. */ 78. private void resize() { 79. //队列容量翻倍 80. int newSize = this.size * 2; 81. this.array = Arrays.copyOf(this.array, newSize); 82. } 83. 84. public static void main(String[] args) throws Exception { 85. PriorityQueue priorityQueue = new PriorityQueue(); 86. priorityQueue.enQueue(3); 87. priorityQueue.enQueue(5); 88. priorityQueue.enQueue(10); 89. priorityQueue.enQueue(2); 90. priorityQueue.enQueue(7); 91. System.out.println(\" 素：\" + priorityQueue.deQueue()); 92. System.out.println(\" 素：\" + priorityQueue.deQueue()); 93. } 堆排序 建堆结束之后，数组中的数据已经是按照大顶堆的特性来组织的。数组中的第一个元素就是堆顶，也就是最大的元素。把它跟最后一个元素交换，那最大元素就放到了下标为 nn 的位置。 当堆顶元素移除之后，把下标为 nn的元素放到堆顶，然后再通过堆化的方法，将剩下的 n−1n−1 个元素重新构建成堆。堆化完成之后再取堆顶的元素，放到下标是 n−1n−1 的位置，一直重复这个过程，直到最后堆中只剩下标为 11 的一个元素，排序工作就完成了。 Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-31 11:24:13 "},"图.html":{"url":"图.html","title":"15.图","keywords":"","body":"图 图的概念 图（Graph）和树比起来，是一种更加复杂的非线性表结构。 顶点与边 树中的元素称为节点，图中的元素叫作顶点（vertex）。图一个顶点可以与任意其他顶点建立连接关系，这种建立的关系叫边（edge）。 在微信中，可以把每个用户看作一个顶点，两个用户之间互加好友，那就在两者之间建立一条边。所以，整个微信的好友关系就可以用一张图来表示。其中，每个用户有多少个好友，对应到图中，就叫作顶点的度（degree），就是跟顶点相连接的边的条数。 有向图&无向图 微博允许单向关注，用户 A 关注了用户 B，但用户 B 可以不关注用户 A。如果用户 A 关注了用户 B，就在图中画一条从 A 到 B 的带箭头的边，来表示边的方向。如果用户 A 和用户 B 互相关注了，那我们就画一条从 A 指向 B 的边，再画一条从 B 指向 A 的边。 这种边有方向的图叫作“有向图”。边没有方向的图就叫作“无向图”。 无向图中的“度”表示一个顶点有多少条边，在有向图中度分为入度（In-degree）和出度（Out-degree）。 顶点的入度，表示有多少条边指向这个顶点；顶点的出度，表示有多少条边是以这个顶点为起点指向其他顶点。 对应到微博的例子，入度就表示有多少粉丝，出度就表示关注了多少人。 带权图 QQ还记录了两个用户之间的亲密度，如果两个用户经常往来，那亲密度就比较高；如果不经常往来，亲密度就比较低。在带权图（weighted graph）中，每条边都有一个权重（weight），可以通过这个权重来表示 QQ 好友间的亲密度。 图的存储 邻接矩阵 邻接矩阵（Adjacency Matrix）的底层依赖一个二维数组。 对于无向图来说，如果顶点 i 与顶点 j 之间有边，就将A[i][j]A[i][j]和A[j][i]A[j][i]标记为 1； 对于有向图来说，如果顶点 i 指向顶点 j 就将A[i][j]A[i][j]标记为1。同理，如果顶点 j 指向顶点 i 就将A[j][i]A[j][i]标记为 1。对于带权图，数组中就存储相应的权重。 邻接矩阵的底层依赖一个二维数组。对于无向图来说，如果顶点 i 与顶点 j 之间有边，我们就将 A[i][j]A[i][j] 和 A[j][i]A[j][i] 标记为 1；对于有向图来说，如果顶点 i 到顶点 j 之间，有一条箭头从顶点 i 指向顶点 j 的边，那我们就将 A[i][j]A[i][j] 标记为 1。同理，如果有一条箭头从顶点 j 指向顶点 i 的边，我们就将 A[j][i]A[j][i] 标记为 1。对于带权图，数组中就存储相应的权重。 用邻接矩阵来表示一个图，虽然简单、直观，但是比较浪费存储空间。为什么这么说呢？ 对于无向图来说，如果 A[i][j]A[i][j] 等于 1，那 A[j][i]A[j][i] 也肯定等于 1，只需要存储上三角矩阵或下三角矩阵可以节省一半的空间。 稀疏图（Sparse Matrix）是指每个顶点的边不多的图，用邻接矩阵的存储方法会非常浪费空间。 比如微信有好几亿的用户，对应到图上有好几亿的顶点，但每个用户的好友一般也就三五百个。如果用邻接矩阵来存储，那绝大部分的存储空间都被浪费了。 但邻接矩阵的存储方式简单、直接，因为基于数组，所以在获取两个顶点的关系时，就非常高效。其次用邻接矩阵的方式存储图，可以将很多图的运算转换成矩阵之间的运算。比如求解最短路径的Floyd-Warshall 算法，就是利用矩阵循环相乘若干次得到结果。 邻接表与逆邻接表 为了解决邻接矩阵占用空间的问题，人们想到了另一种图的表示方法：邻接表。 在邻接表中，图的每一个顶点都是一个链表的头节点，其后连接着该顶点能够直接达到的相邻顶点。 要想查出从顶点0能否到达顶点1，该怎么做呢？很简单，我们从顶点0开始，顺着链表的头节点向后遍历，看看后继的节点中是否存在顶点1。 要想查出顶点0能够到达的所有相邻节点，也很简单，从顶点0向后的所有链表节点，就是顶点0能到达的相邻节点。 那么，要想查出有哪些节点能一步到达顶点1，又该怎么做呢？这样就麻烦一些了，我们要遍历每一个顶点所在的链表，看看链表节点中是否包含节点1，最后发现顶点0和顶点3可以到达顶点1。 像这种逆向查找的麻烦，该如何解决呢？我们可以是用逆邻接表来解决。 逆邻接表顾名思义，和邻接表是正好相反的。逆邻接表每一个顶点作为链表的头节点，后继节点所存储的是能够直接达到该顶点的相邻顶点。 这样一来，要想查出有哪些节点能一步到达顶点1就容易了，从顶点1向后的所有链表节点，就是能一步到达顶点1的节点。 因此，我们可以根据实际需求，选择使用邻接表还是逆邻接表。 十字链表 十字链表长什么样呢？用最直观的示意，是下面这样： 如图所示，十字链表的每一个顶点，都是两个链表的根节点，其中一个链表存储着该顶点能到达的相邻顶点，另一个链表存储着能到达该顶点的相邻节点。 不过，上图只是一个便于理解的示意图，我们没有必要把链表的节点都重复存储两次。在优化之后的十字链表中，链表的每一个节点不再是顶点，而是一条边，里面包含起止顶点的下标。 十字链表节点和边的对应关系，如下图所示： 因此，优化之后的十字链表，是下面这个样子： 图中每一条带有蓝色箭头的链表，存储着从顶点出发的边；每一条带有橙色箭头的链表，存储着进入顶点的边。初学十字链表的时候，可能会觉得有些乱。 总结 1.我们这一次介绍了图的定义和分类。根据图的边是否有方向，可分为有向图和无向图。根据图的边是否有权重，可分为带权**图和无权图**。当然，也可以把两个维度结合起来描述，比如有向带权图，无向无权图等等。 2.图的表示方法有很多种。包括邻接矩阵、邻接表、逆邻接表、十字链表。（还有一种邻接多重表，有兴趣的小伙伴可以自学下） Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-31 13:49:33 "},"DFS and BFS.html":{"url":"DFS and BFS.html","title":"16.深度优先遍历 和 广度优先遍历","keywords":"","body":"BFS&DFS 搜索算法 深度优先搜索算法和广度优先搜索算法都是基于“图”这种数据结构。 图上的搜索算法就是，在图中找出从一个顶点出发，到另一个顶点的路径。图上的搜索算法有深度优先、广度优先搜索算法，和AA*∗、IDAIDA*∗ 等启发式搜索算法。 广度优先搜索和深度优先搜索是图上的两种最常用、最基本的搜索算法，仅适用于状态空间不大的搜索。它们比AA*∗、IDAIDA*∗ 等启发式搜索算法要简单粗暴，没有什么优化，所以也叫作暴力搜索算法。 广度优先搜索，采用地毯式层层推进，从起始顶点开始，依次往外遍历。广度优先搜索需要借助队列来实现，遍历得到的路径就是起始顶点到终止顶点的最短路径。 深度优先搜索，采用回溯思想，适合用递归或栈来实现。遍历得到的路径并不是最短路径。 深度优先和广度优先搜索的时间复杂度都是 O(E)，空间复杂度都是 O(V)。其中E代表边，O代表顶点。 深度优先遍历简称DFS（Depth First Search），广度优先遍历简称BFS（Breadth First Search），它们是遍历图当中所有顶点的两种方式。 这两种遍历方式有什么不同呢？我们来举个栗子： 我们来到一个游乐场，游乐场里有11个景点。我们从景点0开始，要玩遍游乐场的所有景点，可以有什么样的游玩次序呢？ 第一种是一头扎到底的玩法。我们选择一条支路，尽可能不断地深入，如果遇到死路就往回退，回退过程中如果遇到没探索过的支路，就进入该支路继续深入。 在图中，我们首先选择景点1的这条路，继续深入到景点7、景点8，终于发现走不动了（景点旁边的数字代表探索次序）： 于是，我们退回到景点7，然后探索景点10，又走到了死胡同。于是，退回到景点1，探索景点9： 按照这个思路，我们再退回到景点0，后续依次探索景点2、3、5、4、6，终于玩遍了整个游乐场： 像这样先深入探索，走到头再回退寻找其他出路的遍历方式，就叫做深度优先遍历（DFS）。 除了像深度优先遍历这样一头扎到底的玩法以外，我们还有另一种玩法：首先把起点相邻的几个景点玩遍，然后去玩距离起点稍远一些（隔一层）的景点，然后再去玩距离起点更远一些（隔两层）的景点...... 在图中，我们首先探索景点0的相邻景点1、2、3、4： 接着，我们探索与景点0相隔一层的景点7、9、5、6： 最后，我们探索与景点0相隔两层的景点8、10： 像这样一层一层由内而外的遍历方式，就叫做广度优先遍历（BFS）。 深度/广度 优先遍历 的实现 深度优先遍历 首先说说深度优先遍历的实现过程。这里所说的回溯是什么意思呢？回溯顾名思义，就是自后向前，追溯曾经走过的路径。 我们把刚才游乐场的例子抽象成数据结构的图，假如我们依次访问了顶点0、1、7、8，发现无路可走了，这时候我们要从顶点8退回到顶点7。 而后我们探索了顶点10，又无路可走了，这时候我们要从顶点10退回到顶点7，再退回到顶点1。 像这样的自后向前追溯曾经访问过的路径，就叫做回溯。 要想实现回溯，可以利用栈的先入后出特性，也可以采用递归的方式（因为递归本身就是基于方法调用栈来实现）。 下面我们来演示一下具体实现过程。 首先访问顶点0、1、7、8，这四个顶点依次入栈，此时顶点8是栈顶： 从顶点8退回到顶点7，顶点8出栈： 接下来访问顶点10，顶点10入栈： 从顶点10退到顶点7，从顶点7退到顶点1，顶点10和顶点7出栈： 探索顶点9，顶点9入栈： 以此类推，利用这样一个临时栈来实现回溯，最终遍历完所有顶点。 广度优先遍历 接下来该说说广度优先遍历的实现过程了。刚才所说的重放是什么意思呢？似乎听起来和回溯差不多？其实，回溯与重放是完全相反的过程。 仍然以刚才的图为例，按照广度优先遍历的思想，我们首先遍历顶点0，然后遍历了邻近顶点1、2、3、4： 接下来我们要遍历更外围的顶点，可是如何找到这些更外围的顶点呢？我们需要把刚才遍历过的顶点1、2、3、4按顺序重新回顾一遍，从顶点1发现邻近的顶点7、9；从顶点3发现邻近的顶点5、6。 像这样把遍历过的顶点按照之前的遍历顺序重新回顾，就叫做重放。同样的，要实现重放也需要额外的存储空间，可以利用队列的先入先出特性来实现。 下面我们来演示一下具体实现过程。 首先遍历起点顶点0，顶点0入队： 接下来顶点0出队，遍历顶点0的邻近顶点1、2、3、4，并且把它们入队： 然后顶点1出队，遍历顶点1的邻近顶点7、9，并且把它们入队： 然后顶点2出队，没有新的顶点可入队： 以此类推，利用这样一个队列来实现重放，最终遍历完所有顶点。 Copyright © yxm666.github.io/mybook 2019 all right reserved，powered by Gitbook该文章修订时间： 2020-01-31 17:32:23 "}}